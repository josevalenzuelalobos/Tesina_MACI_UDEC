{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Guarda una referencia a la función print original\n",
    "original_print = __builtins__.print\n",
    "\n",
    "# Redefine la función print\n",
    "def print(*args, **kwargs):\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    original_print(current_time, \"-\", *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tesina_utils import calculate_water_index_from_xr_dataset, calculate_fire_index_from_xr_dataset, calculate_vegetation_index_from_xr_dataset, VegetationIndex, FireIndex, WaterIndex, IndexCategory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastkml import  kml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Tuple\n",
    "def polygon_coords_to_px_coords(polygon, width: int, height: int) -> list[Tuple[int, int]]:\n",
    "    \"\"\"Transforms polygon coordinates from lat/lon to pixel coordinates\n",
    "\n",
    "    :param polygon: list of coordinates in lat/lon\n",
    "    :param bbox: bounding box\n",
    "    :param width: width of bounding box in pixels\n",
    "    :param height: height of bounding box in pixels\n",
    "    :return: list of coordinates in pixels\n",
    "    \"\"\"\n",
    "    east1, north1 = polygon.bounds[0], polygon.bounds[1]\n",
    "    east2, north2 = polygon.bounds[2], polygon.bounds[3]\n",
    "    div_x = (east2 - east1) / width\n",
    "    div_y = (north2 - north1) / height\n",
    "\n",
    "    pixel_coords = []\n",
    "\n",
    "    for coord in polygon.exterior.coords:\n",
    "        # Scale and translate the coordinate\n",
    "        px_coord = ((coord[0] - east1) / div_x, (coord[1] - north1) / div_y)\n",
    "        # Append to the list of pixel coordinates\n",
    "        pixel_coords.append(px_coord)\n",
    "    return pixel_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def get_kml_polygon_masks(polygon, width: int, height: int) -> list[Tuple[np.ndarray, np.ndarray]]:\n",
    "    #get the polygon mask\n",
    "    polygon_coords = polygon_coords_to_px_coords(polygon, width, height)\n",
    "    polygon_mask = np.zeros((height, width))\n",
    "    polygon_mask = cv2.fillPoly(polygon_mask, np.array([polygon_coords], dtype=np.int32), 1)\n",
    "    polygon_mask = np.flipud(polygon_mask).astype(np.uint8)\n",
    "    return polygon_mask, np.dstack([polygon_mask] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def equalize_image(image):\n",
    "    \"\"\"\n",
    "    Applies Contrast Limited Adaptive Histogram Equalization (CLAHE) to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    image: ndarray, an RGB image to be equalized.\n",
    "\n",
    "    Returns:\n",
    "    image_clahe: ndarray, the equalized image.\n",
    "    \"\"\"\n",
    "    # Convert the image from RGB to Lab\n",
    "    image_lab = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # Split the Lab channels\n",
    "    l, a, b = cv2.split(image_lab)\n",
    "\n",
    "    # Create the CLAHE object\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "\n",
    "    # Apply CLAHE to the L channel and merge back\n",
    "    l_clahe = clahe.apply(l)\n",
    "    image_lab_clahe = cv2.merge((l_clahe,a,b))\n",
    "\n",
    "    # Convert the image from Lab to BGR\n",
    "    image_clahe = cv2.cvtColor(image_lab_clahe, cv2.COLOR_Lab2BGR)\n",
    "\n",
    "    return image_clahe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class S2Band(Enum):\n",
    "    B01 = 0     # Aerosols\n",
    "    B02 = 1     # Blue, 492.4 nm (S2A), 492.1 nm (S2B)\n",
    "    B03 = 2     # Green, 559.8 nm (S2A), 559 nm (S2B)\n",
    "    B04 = 3     # Red, 664.6 nm (S2A), 665 nm (S2B)\n",
    "    B05 = 4     # Vegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)\n",
    "    B06 = 5     # Vegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)\n",
    "    B07 = 6     # Vegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)\n",
    "    B08 = 7     # NIR, 832.8 nm (S2A), 833 nm (S2B)\n",
    "    B8A = 8     # Narrow NIR, 864.7 nm (S2A), 864 nm (S2B)\n",
    "    B09 = 9     # Water vapour, 945 nm (S2A), 943.2 nm (S2B)\n",
    "\n",
    "class S2BandNames(Enum):\n",
    "    AEROSOLS = 0,\n",
    "    BLUE = 1,\n",
    "    GREEN = 2,\n",
    "    RED = 3,\n",
    "    VEGETATION_RED_EDGE_1 = 4,\n",
    "    VEGETATION_RED_EDGE_2 = 5,\n",
    "    VEGETATION_RED_EDGE_3 = 6,\n",
    "    NIR = 7,\n",
    "    NARROW_NIR = 8,\n",
    "    WATER_VAPOUR = 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def robust_scaler_normalize_images(images):\n",
    "    robust_scaler = RobustScaler()\n",
    "\n",
    "    # Stack all the images into a single numpy array\n",
    "    all_images = np.stack(images)\n",
    "\n",
    "    # Retain the dimensions of the individual images for later\n",
    "    image_shape = all_images.shape[1:]\n",
    "\n",
    "    # Reshape the array so that each row is an image\n",
    "    all_images = all_images.reshape(-1, np.prod(image_shape))\n",
    "\n",
    "    # Normalize all the images at once\n",
    "    all_images_normalized = robust_scaler.fit_transform(all_images)\n",
    "\n",
    "    # Reshape the images back to their original shape\n",
    "    images_normalized = [image.reshape(image_shape) for image in all_images_normalized]\n",
    "\n",
    "    return images_normalized\n",
    "\n",
    "def plot_distribution_before_after_robust_scaler(images, images_normalized):\n",
    "    all_images = np.stack(images).reshape(-1, np.prod(np.stack(images).shape[1:]))\n",
    "    all_images_normalized = np.stack(images_normalized).reshape(-1, np.prod(np.stack(images_normalized).shape[1:]))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Distribution before normalization\n",
    "    sns.histplot(all_images.flatten(), ax=axs[0], color='blue', kde=True)\n",
    "    axs[0].set_title('Distribution before normalization')\n",
    "\n",
    "    # Distribution after normalization\n",
    "    sns.histplot(all_images_normalized.flatten(), ax=axs[1], color='green', kde=True)\n",
    "    axs[1].set_title('Distribution after normalization')\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make directory if it does not exist, concatenate the path from the list of directories\n",
    "def make_dir(dir_list: list):\n",
    "    dir_path = os.path.join(*dir_list)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    return dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "\n",
    "def save_image_with_palette_and_labels(image, directory, filename, palette, labels):\n",
    "    # Create an empty RGB image with the same shape as the input image\n",
    "    rgb_image = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Replace each pixel with the corresponding RGB color in the palette\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            rgb_image[i, j] = palette[image[i, j]]\n",
    "\n",
    "    # Create a legend with percentage of each class\n",
    "    unique_labels, counts = np.unique(image, return_counts=True)\n",
    "    total_pixels = image.size\n",
    "    patches = [mpatches.Patch(color=np.array(palette[label])/255., \n",
    "                label=f\"{labels[label]} [{100 * count / total_pixels:.2f}%]\") \n",
    "                for label, count in zip(unique_labels, counts)]\n",
    "\n",
    "    # Plot the image and the legend\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(rgb_image)\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Combine the directory and filename to form the output path\n",
    "    output_path = os.path.join(directory, filename)\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RGB color mapping for each land cover class\n",
    "land_cover_palette = {\n",
    "    0: (255, 255, 255),  # No data\n",
    "    1: (255, 0, 0),  # Saturated / Defective\n",
    "    2: (0, 0, 0),  # Dark Area Pixels\n",
    "    3: (255, 255, 0),  # Cloud Shadows\n",
    "    4: (0, 255, 0),  # Vegetation\n",
    "    5: (255, 0, 255),  # Bare Soils\n",
    "    6: (0, 0, 255),  # Water\n",
    "    7: (255, 72, 0),  # Clouds low probability / Unclassified\n",
    "    8: (255, 100, 0),  # Clouds medium probability\n",
    "    9: (255, 128, 0),  # Clouds high probability\n",
    "    10: (255, 255, 255),  # Cirrus\n",
    "    11: (255, 255, 255)  # Snow / Ice\n",
    "}\n",
    "\n",
    "# Define descriptive labels for each land cover class\n",
    "land_cover_labels = {\n",
    "    0: 'No data',\n",
    "    1: 'Saturated / Defective',\n",
    "    2: 'Dark Area Pixels',\n",
    "    3: 'Cloud Shadows',\n",
    "    4: 'Vegetation',\n",
    "    5: 'Bare Soils',\n",
    "    6: 'Water',\n",
    "    7: 'Clouds low probability / Unclassified',\n",
    "    8: 'Clouds medium probability',\n",
    "    9: 'Clouds high probability',\n",
    "    10: 'Cirrus',\n",
    "    11: 'Snow / Ice'\n",
    "}\n",
    "\n",
    "land_cover_palette_list = [land_cover_palette[i] for i in range(len(land_cover_palette))]\n",
    "land_cover_palette_array = np.array(land_cover_palette_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_breaks_histogram(break_image, monitoring_start, dates, name=None):\n",
    "    \"\"\"\n",
    "    Plots a histogram of breaks.\n",
    "\n",
    "    Parameters:\n",
    "    break_image: ndarray, an image where each pixel value indicates the break number.\n",
    "    monitoring_start: datetime, the start date of monitoring.\n",
    "    dates: list, list of dates corresponding to break values.\n",
    "    name: str, optional name for the title.\n",
    "    \"\"\"\n",
    "    # Set Seaborn style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Flattened breaks\n",
    "    breaks_flattened = break_image.flatten()\n",
    "\n",
    "    # Remove zeros if you don't want to count them\n",
    "    breaks_flattened = breaks_flattened[breaks_flattened > 0]\n",
    "\n",
    "    # Determine bins based on integer values\n",
    "    bins = np.arange(1, breaks_flattened.max() + 1) - 0.5\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    # Create a histogram with Seaborn\n",
    "    sns.histplot(breaks_flattened, bins=bins, kde=False, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Set integer x-axis ticks\n",
    "    plt.xticks(np.arange(breaks_flattened.min(), breaks_flattened.max() + 1))\n",
    "\n",
    "    # Title\n",
    "    if name is not None:\n",
    "        plt.title(\"Histogram of breaks \" + name + \" \" + str(monitoring_start.date()) + \" - \" + str(dates[-1]))\n",
    "    else:\n",
    "        plt.title(\"Histogram of breaks \" + str(monitoring_start.date()) + \" - \" + str(dates[-1]))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_histogram(data, title, x_label='Value', y_label='Frequency', bins=80, discard_outliers=0.02, discard_value: int = 0):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the given data.\n",
    "\n",
    "    Parameters:\n",
    "    data: ndarray, a 2D array where each pixel value represents a data point.\n",
    "    title: str, the title of the plot.\n",
    "    x_label: str, label for the x-axis.\n",
    "    y_label: str, label for the y-axis.\n",
    "    bins: int, the number of bins in the histogram.\n",
    "    discard_outliers: float, fraction of data points to be discarded from both tails.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set Seaborn style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Flattened data\n",
    "    data_flattened = data.flatten()\n",
    "\n",
    "    # Discard the given fraction of the highest and lowest values\n",
    "    data_flattened = np.sort(data_flattened)[int(len(data_flattened) * discard_outliers):int(len(data_flattened) * (1 - discard_outliers))]\n",
    "\n",
    "    if discard_value is not None:\n",
    "        data_flattened = data_flattened[data_flattened != discard_value]\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    # Create a histogram with Seaborn\n",
    "    sns.histplot(data_flattened, bins=bins, kde=False, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "def save_images_to_folder(images: List[np.ndarray], \n",
    "                          image_names: List[str],                           \n",
    "                          mask: np.ndarray = None,                           \n",
    "                          folder_path: str = './', \n",
    "                          subfolder_name: str = 'images', \n",
    "                          normalize: bool=False) -> None:\n",
    "    \"\"\"\n",
    "    Save images to folder\n",
    "    :param images: images to save\n",
    "    :param mask: mask to apply to images\n",
    "    :param folder_path: path to folder\n",
    "    :param subfolder_name: name of subfolder\n",
    "    :param image_names: names of images\n",
    "    :param normalize: Boolean flag to normalize image or not\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "        \n",
    "    path_to_folder = os.path.join(folder_path, subfolder_name)\n",
    "    os.makedirs(path_to_folder, exist_ok=True)\n",
    "        \n",
    "    if mask is not None:\n",
    "        if mask.ndim == 2:  # If the mask is a single channel\n",
    "            mask = np.repeat(mask[np.newaxis, :, :], 3, axis=0)  # Duplicate the mask channel to match the image's shape\n",
    "\n",
    "\n",
    "        # Save images\n",
    "        for i, image in enumerate(images):\n",
    "            if image.ndim == 2:  # If image is grayscale\n",
    "                masked_image = image * mask[:, :, 0]  # Apply single channel mask\n",
    "            elif image.ndim == 3 and image.shape[2] == 4:  # If image is RGBA\n",
    "                # Apply mask to RGB channels and leave alpha channel intact\n",
    "                masked_image = np.zeros_like(image)\n",
    "                masked_image[:, :, :3] = image[:, :, :3] * mask\n",
    "                masked_image[:, :, 3] = image[:, :, 3]\n",
    "            else:  # If image is RGB\n",
    "                masked_image = image * mask  # Apply multi-channel mask\n",
    "                \n",
    "            if normalize:\n",
    "                masked_image = ((masked_image) / \n",
    "                                (masked_image.max())) * 255\n",
    "            masked_image = masked_image.astype(np.uint8)\n",
    "            masked_image = masked_image.transpose(1, 2, 0)\n",
    "            imageio.imwrite(os.path.join(path_to_folder, image_names[i]), masked_image)\n",
    "    else:\n",
    "        for i, image in enumerate(images):\n",
    "            if normalize:\n",
    "                image = ((image) / \n",
    "                         (image.max())) * 255\n",
    "            image = image.astype(np.uint8)\n",
    "            image = image.transpose(1, 2, 0)\n",
    "            imageio.imwrite(os.path.join(path_to_folder, image_names[i]), image)\n",
    "            \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19 09:23:19 - ['Bosques Bio Bio.kml', 'Incendios.kml', 'Bosques Arauco.kml']\n",
      "2023-10-19 09:23:19 - Processing file: Bosques Bio Bio.kml\n",
      "2023-10-19 09:23:19 - Bosques Bio Bio\n",
      "2023-10-19 09:23:19 - Bosque 1\n",
      "2023-10-19 09:23:19 - Bounding box: (-72.45142890120229, -37.1935384751085, -72.43650978092387, -37.18581491700413)\n",
      "2023-10-19 09:23:19 - Bosque 2\n",
      "2023-10-19 09:23:19 - Bounding box: (-72.42482075716856, -37.16361946111896, -72.41455274852883, -37.15297897451463)\n",
      "2023-10-19 09:23:19 - Bosque 3\n",
      "2023-10-19 09:23:19 - Bounding box: (-72.42423154064022, -37.1722707957546, -72.39075268176586, -37.15535508695594)\n",
      "2023-10-19 09:23:19 - Processing file: Incendios.kml\n",
      "2023-10-19 09:23:19 - Incendios\n",
      "2023-10-19 09:23:19 - Chiguayante 1\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.14301140515278, -36.97713577738772, -73.07640424786813, -36.93275197623442)\n",
      "2023-10-19 09:23:19 - Chiguayante 2\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.14176444168599, -36.9381030333295, -73.0759365158813, -36.8955341536585)\n",
      "2023-10-19 09:23:19 - Chiguayante 3\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.09247710426861, -36.96612752435021, -73.04916885369173, -36.90573403759328)\n",
      "2023-10-19 09:23:19 - Chiguayante 4\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.12606758829688, -36.9081675422274, -73.061031549321, -36.86168173129509)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 1A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.10024648935914, -37.00599908203579, -73.01957953773102, -36.95879313581607)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 2A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.04036737298806, -37.01755151434758, -72.9754469595727, -36.97935311550503)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 3A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.0678219948473, -37.03749423786027, -73.0240416598228, -37.00106229759297)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 4A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.07451558549057, -37.05318473785042, -73.04203319104232, -37.02371822573524)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 5A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.10497931567491, -37.0322744217239, -73.06257786280554, -37.00529420238149)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 6A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.11372556281393, -37.04893748704549, -73.06975694381524, -37.02136071971579)\n",
      "2023-10-19 09:23:19 - Santa Juana Oeste 7A\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.1308187442521, -37.06739916638129, -73.07328966305917, -37.03798667199507)\n",
      "2023-10-19 09:23:19 - Processing file: Bosques Arauco.kml\n",
      "2023-10-19 09:23:19 - Bosques Arauco\n",
      "2023-10-19 09:23:19 - Bosque 1\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.22463404026551, -38.35707144407397, -73.20480742314194, -38.34181702066553)\n",
      "2023-10-19 09:23:19 - Bosque 2\n",
      "2023-10-19 09:23:19 - Bounding box: (-73.41505159496242, -38.33398857570901, -73.37898780445218, -38.30652589165886)\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "#Read kml with forests polygons and convert it to GeoDataFrame\n",
    "#Data is in zones folder, read every file and convert it to GeoDataFrame\n",
    "\n",
    "#Get the list of files from the zones folder\n",
    "files = os.listdir(\"./zones\")\n",
    "print(files)\n",
    "\n",
    "#Create the empty list to store the GeoDataFrame\n",
    "gdf_list = []\n",
    "zone_dict = {}\n",
    "#resolution of the image\n",
    "resolution = 10\n",
    "#Get the data from the sentinel-2\n",
    "km2deg = 1/110.574 # 1km in degrees\n",
    "\n",
    "#Loop through the files\n",
    "for file in files:\n",
    "    print(f'Processing file: {file}')\n",
    "    doc = open(\"./zones/\" + file, \"r\", encoding='utf-8', errors='ignore').read()\n",
    "    k = kml.KML()\n",
    "    \n",
    "    try:\n",
    "        k.from_string(doc.encode('utf-8'))\n",
    "    except etree.ParseError:\n",
    "        print(f\"Unable to parse file: {file}\")\n",
    "        continue\n",
    "\n",
    "    features = list(list(k.features())[0].features())   \n",
    "    for f in features:\n",
    "        print(f.name)\n",
    "        zone_dict[f.name] = {}\n",
    "\n",
    "    polygons = list(features[0].features())\n",
    "    for p in polygons:\n",
    "        print(p.name)\n",
    "        #read polygon and get square of it\n",
    "        polygon = p.geometry\n",
    "        #add polygon to the dictionary\n",
    "        zone_dict[f.name][p.name] = {}\n",
    "        zone_dict[f.name][p.name][\"polygon\"] = polygon\n",
    "        print(\"Bounding box: {}\".format(polygon.bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bounds(bbox, invert_y=False):\n",
    "    \"\"\"\n",
    "    Helper method for changing bounding box representation to leaflet notation\n",
    "\n",
    "    ``(lon1, lat1, lon2, lat2) -> ((lat1, lon1), (lat2, lon2))``\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    if invert_y:\n",
    "        y1, y2 = y2, y1\n",
    "    return ((y1, x1), (y2, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "#import folium\n",
    "#import folium.plugins\n",
    "#import geopandas as gpd\n",
    "#import shapely.geometry\n",
    "from IPython.display import HTML, display\n",
    "from pystac_client import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "from enum import Enum\n",
    "\n",
    "class LogLevel(Enum):\n",
    "    Trace = 0\n",
    "    Debug = 1\n",
    "    Info = 2\n",
    "    Warning = 3\n",
    "    Error = 4\n",
    "    Disabled = 5\n",
    "\n",
    "class Logger:\n",
    "\n",
    "    def __init__(self, min_log_level=LogLevel.Info):\n",
    "        self.min_log_level = min_log_level\n",
    "\n",
    "    def log_message(self, level, message):\n",
    "        if level.value < self.min_log_level.value:\n",
    "            return\n",
    "\n",
    "        if level == LogLevel.Error:\n",
    "            print(colored(message, 'red'))\n",
    "        elif level == LogLevel.Warning:\n",
    "            print(colored(message, 'yellow'))\n",
    "        elif level == LogLevel.Info:\n",
    "            print(colored(message, 'blue'))\n",
    "        elif level == LogLevel.Debug:\n",
    "            print(colored(message, 'cyan'))\n",
    "        elif level == LogLevel.Trace:\n",
    "            print(colored(message, 'magenta'))\n",
    "        else:\n",
    "            print(message)\n",
    "\n",
    "    def error(self, message):\n",
    "        self.log_message(LogLevel.Error, message)\n",
    "\n",
    "    def warning(self, message):\n",
    "        self.log_message(LogLevel.Warning, message)\n",
    "\n",
    "    def info(self, message):\n",
    "        self.log_message(LogLevel.Info, message)\n",
    "\n",
    "    def debug(self, message):\n",
    "        self.log_message(LogLevel.Debug, message)\n",
    "\n",
    "    def trace(self, message):\n",
    "        self.log_message(LogLevel.Trace, message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "def convert_band_uint16_dtype(variable_data):\n",
    "    if variable_data.dtype == 'uint16':\n",
    "        max_value = variable_data.max().values.item()\n",
    "        if max_value <= np.iinfo(np.int16).max:\n",
    "            new_dtype = 'int16'\n",
    "        else:\n",
    "            new_dtype = 'int32'\n",
    "        return variable_data.astype(new_dtype)\n",
    "    else:\n",
    "        return variable_data\n",
    "\n",
    "def fetch_or_cache_stac_data_by_band_and_month(catalog, bands, collections, start_date:str, end_date:str, limit, bbox, cloud_cover, resolution, stac_config=None, crs=\"EPSG:4326\", cache_dir='data_cache', force_download=False, log_level: LogLevel = LogLevel.Info, save_rgb_image=False):\n",
    "\n",
    "    logger = Logger(min_log_level=log_level)\n",
    "    start_date_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    current_date_dt = datetime.now()\n",
    "\n",
    "    combined_data = []  # List to hold the data for each month\n",
    "    properties = []  # List to hold the properties for each month\n",
    "\n",
    "    current_month_start = start_date_dt\n",
    "    while current_month_start <= end_date_dt:    \n",
    "        range_properties = []  # List to hold the properties for a specific month\n",
    "        logger.debug(f\"Processing month {current_month_start.date()} - {current_month_start + pd.DateOffset(months=1) - pd.DateOffset(minutes=1)}\")\n",
    "        # Determine the date range for the cache file\n",
    "        cache_start_date = current_month_start\n",
    "        cache_end_date = min(current_month_start + pd.DateOffset(months=1), end_date_dt)\n",
    "        if cache_end_date > current_date_dt:\n",
    "            cache_end_date = current_date_dt\n",
    "\n",
    "        cache_start_date_str = cache_start_date.strftime(\"%Y-%m-%d\")\n",
    "        cache_end_date_str = cache_end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        group_data_list = []\n",
    "        bands_to_download = []\n",
    "        bands_to_skip = []\n",
    "        dims = None\n",
    "        items = None\n",
    "\n",
    "        if force_download:\n",
    "            logger.info(f\"Force download data for all bands\")\n",
    "            bands_to_download = bands\n",
    "        else:   \n",
    "            # Check for each band\n",
    "            for band in bands:\n",
    "                metadata_str = f\"{collections}_{cache_start_date_str}_{cache_end_date_str}_{limit}_{bbox}_{cloud_cover}_{stac_config}_{resolution}_{crs}_{band}\"\n",
    "                metadata_hash = hashlib.md5(metadata_str.encode()).hexdigest()\n",
    "                cache_filepath = os.path.join(cache_dir, f\"{metadata_hash}.nc\")\n",
    "\n",
    "                if os.path.exists(cache_filepath):\n",
    "                    bands_to_skip.append(band)\n",
    "                    band_data = xr.open_dataset(cache_filepath)\n",
    "                    variable_data =  band_data[band]\n",
    "                    invalid_values_count = variable_data.isnull().sum() + (variable_data == 0).sum()\n",
    "                    invalid_values_percent = (invalid_values_count / variable_data.size).values\n",
    "\n",
    "                    # If more of 5% of the data is NaN or 0 then re-download the data\n",
    "                    if invalid_values_percent > 0.05 and band != 'wvp':\n",
    "                        logger.warning(f\"Data found in cache for band {band} but {invalid_values_percent*100}% of the data is NaN or 0. Re-downloading data\")\n",
    "                        # Remove the file\n",
    "                        os.remove(cache_filepath)\n",
    "                        bands_to_download.append(band)\n",
    "                        bands_to_skip.remove(band)\n",
    "                    elif 'time' in band_data.coords:\n",
    "                        group_data_list.append(band_data)\n",
    "                    else:\n",
    "                        logger.error(f\"Data found in cache for band {band} but it does not have a 'time' dimension. Skipping\")\n",
    "                        bands_to_download.append(band)\n",
    "                        bands_to_skip.remove(band)\n",
    "                else:\n",
    "                    bands_to_download.append(band)\n",
    "                \n",
    "            if len(bands_to_skip) == len(bands):\n",
    "                logger.debug(f\"Data found in cache for all bands. Skipping download\")\n",
    "            elif len(bands_to_skip) > 0:\n",
    "                logger.info(f\"Data found in cache for bands {bands_to_skip}. Downloading data for bands {bands_to_download}\")\n",
    "        \n",
    "        prop_metadata_str = f\"{collections}_{cache_start_date_str}_{cache_end_date_str}_{limit}_{bbox}_{cloud_cover}_{stac_config}_{resolution}_{crs}\"\n",
    "        prop_metadata_hash = hashlib.md5(prop_metadata_str.encode()).hexdigest()\n",
    "        prop_cache_filepath = os.path.join(cache_dir, f\"{prop_metadata_hash}.json\")\n",
    "\n",
    "        if os.path.exists(prop_cache_filepath):\n",
    "            logger.debug(f\"Data found in cache for month {current_month_start.date()} - {current_month_start + pd.DateOffset(months=1) - pd.DateOffset(minutes=1)}\")\n",
    "            with open(prop_cache_filepath, 'r') as f:\n",
    "                range_properties = json.load(f)\n",
    "\n",
    "        if bands_to_download or len(range_properties) == 0:\n",
    "            if collections ==  [\"sentinel-2-l2a\"]:\n",
    "                query = catalog.search(\n",
    "                    collections=collections,\n",
    "                    datetime=f\"{cache_start_date_str}/{cache_end_date_str}\",\n",
    "                    limit=limit,\n",
    "                    bbox=bbox,\n",
    "                    #query=[f'eo:cloud_cover<={cloud_cover}']\n",
    "                )\n",
    "            else:\n",
    "                query = catalog.search(\n",
    "                    collections=collections,\n",
    "                    datetime=f\"{cache_start_date_str}/{cache_end_date_str}\",\n",
    "                    limit=limit,\n",
    "                    bbox=bbox,\n",
    "                )\n",
    "            \n",
    "            items = list(query.get_items())\n",
    "            if len(items) != 0:\n",
    "                #list with item properties to json\n",
    "                range_properties = [item.properties for item in items]\n",
    "                logger.info(f\"Saving properties for month {current_month_start.date()} - {current_month_start + pd.DateOffset(months=1) - pd.DateOffset(minutes=1)}\")\n",
    "                with open(prop_cache_filepath, 'w') as f:\n",
    "                    json.dump(range_properties, f)\n",
    "                \n",
    "                if collections ==  [\"sentinel-2-l1c\"]:\n",
    "                    for i in items:\n",
    "                        for a in i.assets:\n",
    "                            i.assets[a].href = i.assets[a].href.replace('sentinel-s2-l2a', 'sentinel-s2-l1c')\n",
    "\n",
    "                data = stac_load(items, resolution=10, bands=bands_to_download, bbox=bbox, stac_cfg=stac_config, groupby='solar_day', crs=crs)\n",
    "\n",
    "\n",
    "                #if there is data to download\n",
    "                if len(data) > 0:\n",
    "                    # Filter for the month\n",
    "                    month_data = data.sel(time=slice(cache_start_date_str, cache_end_date_str))\n",
    "                \n",
    "                    #print shape (w,h)\n",
    "                    if dims is None:\n",
    "                        dims = month_data.dims\n",
    "                    \n",
    "                    # Check if the data is the expected shape is smaller than expected then raise an error\n",
    "                    if month_data.dims['x'] < dims['x'] or month_data.dims['y'] < dims['y']:\n",
    "                        raise Exception(f\"Data for bands {bands_to_download} is smaller than expected. Expected shape: {dims}. Actual shape: {month_data.dims}\")\n",
    "\n",
    "                    # Compute and save each band                    \n",
    "                    logger.info(f\"Saving data for bands {bands_to_download}\")   \n",
    "                    #print only date part             \n",
    "                    logger.info(f\"Dates for bands: {', '.join([date.strftime('%Y-%m-%d') for date in month_data.time.dt.date.values])}\")\n",
    "\n",
    "\n",
    "                    for band in bands_to_download:\n",
    "                        metadata_str = f\"{collections}_{cache_start_date_str}_{cache_end_date_str}_{limit}_{bbox}_{cloud_cover}_{stac_config}_{resolution}_{crs}_{band}\"\n",
    "                        metadata_hash = hashlib.md5(metadata_str.encode()).hexdigest()\n",
    "                        cache_filepath = os.path.join(cache_dir, f\"{metadata_hash}.nc\")\n",
    "\n",
    "                        band_data = month_data[band].compute()\n",
    "\n",
    "                        if 'time' not in band_data.coords:\n",
    "                            logger.error(f\"Data for band {band} does not have a 'time' dimension. Here are the coordinates: {band_data.coords}\")\n",
    "                            continue\n",
    "                        \n",
    "                        # If more of 50% of the data is NaN or 0 print a warning (check by date and band)\n",
    "                        # Create a list to store the dates that you want to keep\n",
    "                        valid_dates = []\n",
    "\n",
    "                        for date in band_data['time']:\n",
    "                            # Select the data for the current date\n",
    "                            date_data = band_data.sel(time=date)\n",
    "\n",
    "                            # Calculate the number of NaN values\n",
    "                            nan_count = date_data.isnull().sum().values\n",
    "\n",
    "                            # Calculate the number of 0 values\n",
    "                            zero_count = (date_data == 0).sum().values\n",
    "\n",
    "                            # Calculate the total percentage of NaN or zero values\n",
    "                            invalid_values_percent = (nan_count + zero_count) / date_data.size\n",
    "\n",
    "                            # Make a decision based on that percentage\n",
    "                            if invalid_values_percent > 0.05 and band != 'wvp':\n",
    "                                logger.warning(f\"{invalid_values_percent*100}% of the data for band {band} at date {date.values} is NaN or 0. Skipping.\")\n",
    "                            else:\n",
    "                                valid_dates.append(date.values)\n",
    "\n",
    "                        # Filter band_data to only the valid dates\n",
    "                        band_data = band_data.sel(time=valid_dates)\n",
    "\n",
    "                        if len(band_data.time) == 0:\n",
    "                            logger.warning(f\"No valid data found for band {band}. Skipping\")\n",
    "                            continue\n",
    "                        \n",
    "                        logger.info(f\"Saving data for band {band} to {cache_filepath}. Shape: {band_data.shape}\")\n",
    "                        \n",
    "                        band_data.to_netcdf(cache_filepath, engine='netcdf4')\n",
    "                        group_data_list.append(band_data)\n",
    "            else:\n",
    "                logger.warning(f\"No data found for bands {bands_to_download}\")\n",
    "\n",
    "        properties += range_properties\n",
    "        \n",
    "        if len(group_data_list) == len(bands):\n",
    "            group_data_list = [ds.drop_vars('spatial_ref') for ds in group_data_list]\n",
    "            # Combine the bands for this month\n",
    "            group_data = xr.merge(group_data_list)\n",
    "            combined_data.append(group_data)\n",
    "            \n",
    "        if save_rgb_image and len(bands_to_download) > 0:\n",
    "            # Check if the RGB image is in group_data_list\n",
    "            rgb_bands = ['red', 'green', 'blue']\n",
    "            if all(band in group_data_list for band in rgb_bands):\n",
    "                # Take the first image in the month\n",
    "                rgb_data = group_data_list[0][rgb_bands]\n",
    "        # Move to the next month\n",
    "        current_month_start += pd.DateOffset(months=1)\n",
    "\n",
    "    for i, ds in enumerate(combined_data):\n",
    "        if 'time' not in ds.coords:\n",
    "            logger.error(f\"The dataset for month {i} does not have a 'time' dimension. Here are the coordinates: {ds.coords}\")\n",
    "            print(ds.coords)\n",
    "        \n",
    "    # Concatenate the monthly data along the time dimension\n",
    "    final_data = xr.concat(combined_data, dim='time', coords='minimal')\n",
    "    # Remove redundant time values\n",
    "    final_data = final_data.sel(time=~final_data.indexes['time'].duplicated())\n",
    "    logger.debug(\"Concatenated data\")\n",
    "\n",
    "    # Initialize an empty list to collect times with NaN values\n",
    "    nan_times_list = []\n",
    "\n",
    "    for band in bands:\n",
    "        data_array = final_data[band]\n",
    "        numpy_array = data_array.data  # This is a NumPy array\n",
    "        \n",
    "        # Check for NaN in the NumPy array\n",
    "        where_nan = np.isnan(numpy_array)\n",
    "        \n",
    "        # Sum along all dimensions to find any slice along 'time' that contains at least one NaN\n",
    "        nan_along_time = np.any(where_nan, axis=(1, 2))  # Here I assumed the time is the first dimension\n",
    "        \n",
    "        # Retrieve the corresponding time values\n",
    "        times_with_nan = data_array['time'].values[nan_along_time]\n",
    "        if len(times_with_nan) > 0:            \n",
    "            #nan_times_list.extend(np.unique(times_with_nan.values))\n",
    "            nan_times_list.extend(times_with_nan)\n",
    "            logger.debug(f\"Band {band} has NaN values on the following dates: {times_with_nan}\")\n",
    "\n",
    "    # Remove duplicates from the list\n",
    "    unique_nan_times = list(set(nan_times_list))\n",
    "\n",
    "    logger.warning(f\"Unique dates with NaN values across all bands: {unique_nan_times}\")\n",
    "\n",
    "    # Filter out the dates with NaN values from final_data\n",
    "    final_data = final_data.sel(time=~final_data['time'].isin(unique_nan_times))\n",
    "\n",
    "    # Remove elements from properties that are duplicated in datetime\n",
    "    xr_times = final_data['time'].values.astype(str).tolist()\n",
    "\n",
    "    seen = set()\n",
    "    filtered_properties = [seen.add(d['datetime'][:10]) or d for d in properties if d['datetime'][:10] not in seen]\n",
    "    final_properties = [d for d in filtered_properties if d['datetime'][:19] in {x[:19] for x in xr_times}]\n",
    "    sorted_final_properties = sorted(final_properties, key=lambda x: x['datetime'])\n",
    "\n",
    "    logger.debug(\"End of stac_load\")\n",
    "    return final_data, sorted_final_properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def classify_sunny_cloudy_dates_by_scene_classification(ds: xr.Dataset, thresholds: dict, mask: Optional[np.ndarray] = None) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Classify dates in xarray dataset as sunny or cloudy based on the SCL band and thresholds.\n",
    "\n",
    "    Args:\n",
    "    - ds (xr.Dataset): xarray dataset containing Sentinel-2 bands.\n",
    "    - thresholds (dict): Dictionary containing cloud coverage criteria.\n",
    "    - mask (np.ndarray, optional): Binary mask to filter the region of interest. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[List[str], List[str]]: Two lists of dates categorized as sunny and cloudy.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger = Logger(min_log_level=LogLevel.Info)\n",
    "    sunny_dates = []\n",
    "    cloudy_dates = []\n",
    "\n",
    "    for t in ds.time.values:\n",
    "        # Calculate percentages for the specific date\n",
    "        current_scl = ds['scl'].sel(time=t).data\n",
    "        \n",
    "        # Apply the mask to the current_scl if provided\n",
    "        if mask is not None:\n",
    "            masked_scl = current_scl * mask\n",
    "        else:\n",
    "            masked_scl = current_scl\n",
    "        \n",
    "        if mask is not None:\n",
    "            total_pixels = np.sum(mask)  # Total pixels are the sum of the mask\n",
    "        else:\n",
    "            total_pixels = current_scl.size  # Original total pixels\n",
    "\n",
    "        cloud_cover_percent = 100 * (np.sum((masked_scl == 7) | (masked_scl == 8) | (masked_scl == 9)) / total_pixels)\n",
    "        low_proba_clouds_percent = 100 * (np.sum(masked_scl == 7) / total_pixels)\n",
    "        medium_proba_clouds_percent = 100 * (np.sum(masked_scl == 8) / total_pixels)\n",
    "        high_proba_clouds_percent = 100 * (np.sum(masked_scl == 9) / total_pixels)\n",
    "        thin_cirrus_percent = 100 * (np.sum(masked_scl == 10) / total_pixels)\n",
    "        cloud_shadow_percent = 100 * (np.sum(masked_scl == 3) / total_pixels)\n",
    "\n",
    "        if any([cloud_cover_percent, medium_proba_clouds_percent, high_proba_clouds_percent, thin_cirrus_percent, cloud_shadow_percent]):\n",
    "            logger.debug(f\"Date: {t}. Cloud cover: {cloud_cover_percent}. Medium proba clouds: {medium_proba_clouds_percent}. High proba clouds: {high_proba_clouds_percent}. Thin cirrus: {thin_cirrus_percent}. Cloud shadow: {cloud_shadow_percent}\")\n",
    "        \n",
    "        properties = {\n",
    "            'eo:cloud_cover': cloud_cover_percent,\n",
    "            's2:low_proba_clouds_percentage': low_proba_clouds_percent, \n",
    "            's2:medium_proba_clouds_percentage': medium_proba_clouds_percent,\n",
    "            's2:high_proba_clouds_percentage': high_proba_clouds_percent,\n",
    "            's2:thin_cirrus_percentage': thin_cirrus_percent,\n",
    "            's2:cloud_shadow_percentage': cloud_shadow_percent\n",
    "        }\n",
    "\n",
    "        # Check thresholds\n",
    "        if all(properties[key] < value for key, value in thresholds.items()):\n",
    "            sunny_dates.append(str(t))\n",
    "        else:\n",
    "            cloudy_dates.append(str(t))\n",
    "            logger.trace(f\"Cloudy date: {t}\")\n",
    "            for key, value in thresholds.items():\n",
    "                if properties[key] >= value:\n",
    "                    logger.debug(f\"Cloudy date: {t}. Coverage {key} exceeded threshold {value}, value was {properties[key]}\")\n",
    "                    \n",
    "    # Convert to datetime64\n",
    "    sunny_dates = np.array(sunny_dates, dtype='datetime64')\n",
    "    cloudy_dates = np.array(cloudy_dates, dtype='datetime64')\n",
    "\n",
    "    return sunny_dates, cloudy_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_with_palette_and_labels(images, directory, filenames, palette, labels, overwrite=False):\n",
    "    for image, filename in zip(images, filenames):        \n",
    "        output_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check if the file exists at the beginning\n",
    "        if os.path.exists(output_path) and not overwrite:\n",
    "            #print(f\"File {output_path} already exists! Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        rgb_image = palette[image]\n",
    "        unique_labels, counts = np.unique(image, return_counts=True)\n",
    "        total_pixels = image.size\n",
    "        patches = [mpatches.Patch(color=np.array(palette[label]) / 255.,\n",
    "                                  label=f\"{labels[label]} [{100 * count / total_pixels:.2f}%]\")\n",
    "                   for label, count in zip(unique_labels, counts)]\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.savefig(output_path, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def normalize_image_percentile(image, lower_percentile=1, upper_percentile=99):\n",
    "    \"\"\"Normaliza la imagen utilizando percentiles.\"\"\"\n",
    "    lower = np.percentile(image, lower_percentile)\n",
    "    upper = np.percentile(image, upper_percentile)\n",
    "    image = np.clip(image, lower, upper)\n",
    "    return (image - lower) / (upper - lower)\n",
    "\n",
    "\n",
    "def save_images_with_palette_and_labels(images, directory, filenames, palette, labels, \n",
    "                                        overwrite=False, visible_images=None, mask=None):\n",
    "    \n",
    "    \n",
    "    # Si se proporcionan imágenes visibles, deben tener la misma longitud que las imágenes originales\n",
    "    if visible_images is not None:\n",
    "        assert len(images) == len(visible_images), \"Images and visible_images must have the same length\"\n",
    "    \n",
    "    if mask is not None:\n",
    "            mask = np.repeat(mask[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    for idx, (image, filename) in enumerate(zip(images, filenames)):\n",
    "        output_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check if the file exists at the beginning\n",
    "        if os.path.exists(output_path) and not overwrite:\n",
    "            continue\n",
    "        \n",
    "        rgb_image = palette[image]\n",
    "         \n",
    "        # Calculate aspect ratio\n",
    "        height, width = image.shape[:2]\n",
    "        aspect_ratio = height / width\n",
    "\n",
    "        # Adjust figure height based on aspect ratio\n",
    "        if visible_images is not None:\n",
    "            fig_width = 22\n",
    "            fig_height = (fig_width * aspect_ratio) / 1.8  # We divide by 2 because two images will be shown side by side\n",
    "        else:\n",
    "            fig_width = 10\n",
    "            fig_height = fig_width * aspect_ratio\n",
    "\n",
    "        if mask is not None:\n",
    "            assert rgb_image.shape == mask.shape, \"Image and mask must have the same shape\"\n",
    "            rgb_image = rgb_image * mask\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "        unique_labels, counts = np.unique(image, return_counts=True)\n",
    "        total_pixels = image.size\n",
    "        patches = [mpatches.Patch(color=np.array(palette[label]) / 255.,\n",
    "                                  label=f\"{labels[label]} [{100 * count / total_pixels:.2f}%]\")\n",
    "                   for label, count in zip(unique_labels, counts)]\n",
    "\n",
    "        \n",
    "        # If there's a visible_image in the list, we show it alongside the original image\n",
    "        if visible_images is not None:\n",
    "            visible_image = visible_images[idx].transpose(1, 2, 0)\n",
    "            if mask is not None:\n",
    "                visible_image = visible_image * mask\n",
    "            visible_image = normalize_image_percentile(visible_image)  # Normalización usando percentiles\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(visible_image)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "\n",
    "        plt.imshow(rgb_image)\n",
    "        plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.savefig(output_path, bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def process_and_save_images(bands, sunny_dates, cloudy_dates, properties, output_folder, mask, overwrite=False):\n",
    "    \"\"\"\n",
    "    Process and save images based on given dates and properties.\n",
    "\n",
    "    Args:\n",
    "    bands: xarray dataset containing image bands\n",
    "    sunny_dates: list of datetime64 objects representing sunny dates\n",
    "    cloudy_dates: list of datetime64 objects representing cloudy dates\n",
    "    properties: list of properties used to determine image classification\n",
    "    output_folder: str, path to output folder\n",
    "    mask: array-like object used to mask images\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    logger = Logger(min_log_level=LogLevel.Debug)\n",
    "\n",
    "    # Create the visible images\n",
    "    visible_images = [(img / img.max()).astype(np.float32) for img in \n",
    "                      [bands.sel(time=time)[[\"red\", \"green\", \"blue\"]].to_array().values for time in bands.time.values]]\n",
    "\n",
    "    # List of names for the images with dates\n",
    "    images_names = [f\"{str(date)[:10]}.png\" for date in bands.time.values]\n",
    "\n",
    "    # Check if the properties have changed\n",
    "    json_path = os.path.join(output_folder, 'visible', 'properties.json')\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            existing_properties = json.load(f)\n",
    "            if existing_properties != properties:\n",
    "                # If properties change, clear content of the 'visible' folder\n",
    "                for root, dirs, files in os.walk(os.path.join(output_folder, 'visible'), topdown=False):\n",
    "                    for name in files:\n",
    "                        os.remove(os.path.join(root, name))\n",
    "                    for name in dirs:\n",
    "                        os.rmdir(os.path.join(root, name))\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(properties, f)\n",
    "    else:\n",
    "        if not os.path.exists(os.path.join(output_folder, 'visible')):\n",
    "            os.makedirs(os.path.join(output_folder, 'visible'))\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(properties, f)\n",
    "\n",
    "    sunny_images = []\n",
    "    sunny_image_names = []\n",
    "    \n",
    "    cloudy_images = []\n",
    "    cloudy_image_names = []\n",
    "    \n",
    "    unclassified_images = []\n",
    "    unclassified_image_names = []\n",
    "\n",
    "    # Classify images into their corresponding lists\n",
    "    for img, img_name in zip(visible_images, images_names):\n",
    "        date_str = img_name.split('.')[0]\n",
    "        current_date = np.datetime64(date_str, 'D')  # Convert to just date (ignoring time)\n",
    "        if current_date in [np.datetime64(date, 'D') for date in sunny_dates]:\n",
    "            sunny_images.append(img)\n",
    "            sunny_image_names.append(img_name)\n",
    "        elif current_date in [np.datetime64(date, 'D') for date in cloudy_dates]:\n",
    "            cloudy_images.append(img)\n",
    "            cloudy_image_names.append(img_name)\n",
    "        else:\n",
    "            unclassified_images.append(img)\n",
    "            unclassified_image_names.append(img_name)\n",
    "\n",
    "    # Save images for each category\n",
    "    if sunny_images:\n",
    "        save_path = os.path.join(output_folder, 'visible')\n",
    "        save_images_to_folder(sunny_images, sunny_image_names, mask, save_path, 'sunny', True)\n",
    "    \n",
    "    if cloudy_images:\n",
    "        save_path = os.path.join(output_folder, 'visible')\n",
    "        save_images_to_folder(cloudy_images, cloudy_image_names, mask, save_path, 'cloudy', True)\n",
    "    \n",
    "    if unclassified_images:\n",
    "        save_path = os.path.join(output_folder, 'visible')\n",
    "        save_images_to_folder(unclassified_images, unclassified_image_names, mask, save_path, 'unclassified', True)\n",
    "        \n",
    "    logger.info('Visible images saved')\n",
    "        \n",
    "    if 'scl' in bands.data_vars:\n",
    "        # Obtener imágenes 'scl' para todas las fechas\n",
    "        scl_images = [bands.sel(time=time)['scl'].values.astype(np.uint8) for time in bands.time.values]\n",
    "        \n",
    "        # Crear nombres scl\n",
    "        scl_names = [img_name.replace('.png', '_scl.png') for img_name in images_names]\n",
    "\n",
    "        # Clasificar imágenes 'scl' en sus listas correspondientes\n",
    "        sunny_scl_images = []\n",
    "        cloudy_scl_images = []\n",
    "        unclassified_scl_images = []\n",
    "\n",
    "        sunny_scl_names = []\n",
    "        cloudy_scl_names = []\n",
    "        unclassified_scl_names = []\n",
    "\n",
    "        for scl_img, img_name, scl_name in zip(scl_images, images_names, scl_names):\n",
    "            date_str = img_name.split('.')[0]\n",
    "            current_date = np.datetime64(date_str, 'D')\n",
    "            if current_date in [np.datetime64(date, 'D') for date in sunny_dates]:\n",
    "                sunny_scl_images.append(scl_img)\n",
    "                sunny_scl_names.append(scl_name)\n",
    "            elif current_date in [np.datetime64(date, 'D') for date in cloudy_dates]:\n",
    "                cloudy_scl_images.append(scl_img)\n",
    "                cloudy_scl_names.append(scl_name)\n",
    "            else:\n",
    "                unclassified_scl_images.append(scl_img)\n",
    "                unclassified_scl_names.append(scl_name)\n",
    "\n",
    "        # Guardar las imágenes 'scl' con sufijo '_scl' en el nombre del archivo\n",
    "        if sunny_scl_images:\n",
    "            save_path = os.path.join(output_folder, 'visible', 'sunny')\n",
    "            save_images_with_palette_and_labels(sunny_scl_images, save_path, sunny_scl_names, land_cover_palette_array, land_cover_labels, visible_images=sunny_images, overwrite=overwrite, mask=mask)\n",
    "        if cloudy_scl_images:\n",
    "            save_path = os.path.join(output_folder, 'visible', 'cloudy')\n",
    "            save_images_with_palette_and_labels(cloudy_scl_images, save_path, cloudy_scl_names, land_cover_palette_array, land_cover_labels, visible_images=cloudy_images, overwrite=overwrite, mask=mask)\n",
    "        if unclassified_scl_images:\n",
    "            save_path = os.path.join(output_folder, 'visible', 'unclassified')\n",
    "            save_images_with_palette_and_labels(unclassified_scl_images, save_path, unclassified_scl_names, land_cover_palette_array, land_cover_labels, visible_images=unclassified_images, overwrite=overwrite, mask=mask)\n",
    "\n",
    "        logger.info('SCL images saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "\n",
    "def interactive_image_plotter_index(rgb_images, index_images, dates, mask = None, name= None):\n",
    "    \n",
    "    vmin_all = np.min(index_images)\n",
    "    vmax_all = np.max(index_images)\n",
    "    print(f\"Valor mínimo: {vmin_all}\")\n",
    "    print(f\"Valor máximo: {vmax_all}\")\n",
    "    \n",
    "    if mask is not None:\n",
    "        mask3 = np.repeat(mask[:, :, np.newaxis], 3, axis=2)\n",
    "   \n",
    "    def plot_images(date_index, threshold_a, threshold_b):\n",
    "        \"\"\"\n",
    "        Dibuja un par de imágenes RGB e índice basado en el índice de fecha seleccionado.\n",
    "        \"\"\"        \n",
    "        nonlocal selected_date\n",
    "        selected_date.value = f\"Fecha seleccionada: {dates[date_index].strftime('%Y-%m-%d')}\"\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        transposed_rgb = rgb_images[date_index].transpose((1, 2, 0))\n",
    "        transposed_rgb = transposed_rgb * mask3 if mask is not None else transposed_rgb\n",
    "        transposed_rgb = normalize_image_percentile(transposed_rgb)\n",
    "        \n",
    "        # Mostrar imagen RGB\n",
    "        ax1.imshow(transposed_rgb)\n",
    "        ax1.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} RGB')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        index_img = index_images[date_index]\n",
    "        normed_img = (index_img - threshold_a) / (threshold_b - threshold_a)  # Normalize the data\n",
    "        my_cmap = matplotlib.colormaps['viridis']\n",
    "        colored_img = my_cmap(normed_img)\n",
    "        colored_img = colored_img[:, :, :3]\n",
    "\n",
    "        threshold_mask = (index_img > threshold_a) & (index_img < threshold_b)\n",
    "        threshold_mask3 = np.repeat(threshold_mask[:, :, np.newaxis], 3, axis=2)\n",
    "        \n",
    "        masked_img = colored_img * threshold_mask3  * mask3 if mask is not None else colored_img * threshold_mask3\n",
    "\n",
    "        # Mostrar imagen de índice\n",
    "        cax = ax2.imshow(masked_img, cmap='viridis', vmin=threshold_a, vmax=threshold_b)\n",
    "        if name is not None:\n",
    "            ax2.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} {name}')\n",
    "        else:\n",
    "            ax2.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} Índice')\n",
    "        ax2.axis('off')\n",
    "        cbar = plt.colorbar(cax, ax=ax2)\n",
    "        cbar.set_label('Valor del Índice', rotation=270, labelpad=20)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    threshold_a = widgets.BoundedFloatText(\n",
    "        value=vmin_all,  # Inicializar al mínimo global\n",
    "        min=vmin_all,    # Establecer el mínimo permisible\n",
    "        max=vmax_all,    # Establecer el máximo permisible\n",
    "        step=0.01,\n",
    "        description='Umbral A:',\n",
    "    )\n",
    "\n",
    "    threshold_b = widgets.BoundedFloatText(\n",
    "        value=vmax_all,  # Inicializar al máximo global\n",
    "        min=vmin_all,    # Establecer el mínimo permisible\n",
    "        max=vmax_all,    # Establecer el máximo permisible\n",
    "        step=0.01,\n",
    "        description='Umbral B:',\n",
    "    )\n",
    "    \n",
    "    # Create slider widget for date selection\n",
    "    date_slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(dates) - 1,\n",
    "        step=1,\n",
    "        description='Index:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "    date_slider.layout.width = '500px'\n",
    "    date_slider.index = dates\n",
    "    \n",
    "    # Create buttons for easier navigation\n",
    "    prev_button = widgets.Button(description=\"Previous\")\n",
    "    next_button = widgets.Button(description=\"Next\")\n",
    "    \n",
    "    def on_prev_button_clicked(b):\n",
    "        date_slider.value = max(0, date_slider.value - 1)\n",
    "\n",
    "    def on_next_button_clicked(b):\n",
    "        date_slider.value = min(len(dates) - 1, date_slider.value + 1)\n",
    "    \n",
    "   \n",
    "        \n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    \n",
    "    # Create a label to display the selected date\n",
    "    selected_date = widgets.Label(value=\"\")\n",
    "\n",
    "    # Create the interactive plot\n",
    "    interactive_plot = widgets.interactive(plot_images, date_index=date_slider, threshold_a=threshold_a, threshold_b=threshold_b)\n",
    "    \n",
    "    # Show the widgets\n",
    "    display(widgets.HBox([prev_button, next_button]), selected_date, interactive_plot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "\n",
    "def interactive_image_plotter(data:xr.Dataset, dates, mask = None):\n",
    "    \n",
    "    rgb_images = [(img / img.max()).astype(np.float32) for img in \n",
    "                  [data.sel(time=time)[[\"red\", \"green\", \"blue\"]].to_array().values for time in data.time.values]]\n",
    "    \n",
    "    index_images = None\n",
    "    \n",
    "    index_category = None\n",
    "    index_type = None\n",
    "    \n",
    "    # Diccionarios para los índices\n",
    "    index_categories = {\n",
    "        \"Vegetativo\": [e.name for e in VegetationIndex],\n",
    "        \"Fuego\": [e.name for e in FireIndex],\n",
    "        \"Agua\": [e.name for e in WaterIndex]\n",
    "    }\n",
    "\n",
    "    # Dropdown para Tipo de Índice\n",
    "    index_category_selector = widgets.Dropdown(\n",
    "        options=[\"Vegetativo\", \"Fuego\", \"Agua\"],\n",
    "        description='Tipo de Índice:',\n",
    "        disabled=False,\n",
    "        value=None\n",
    "    )\n",
    "\n",
    "    # Dropdown para Índice Específico\n",
    "    index_type_selector = widgets.Dropdown(\n",
    "        options=index_categories[\"Vegetativo\"],\n",
    "        description='Índice Específico:',\n",
    "        disabled=False,\n",
    "        value=None\n",
    "    )\n",
    "\n",
    "    # Actualizar opciones de índice cuando cambia el tipo de índice\n",
    "    def update_index_category(change):\n",
    "        global index_category\n",
    "        index_category = change['new']\n",
    "        index_type_selector.options = index_categories[index_category]\n",
    "        index_type_selector.value = None\n",
    "        threshold_a.disabled = True\n",
    "        threshold_b.disabled = True\n",
    "           \n",
    "    def update_index_type(change):\n",
    "        global index_images, index_type, index_category, vmin_all, vmax_all\n",
    "        index_type = change['new']\n",
    "\n",
    "        if index_category == \"Vegetativo\":\n",
    "            enum_index_type = VegetationIndex[index_type]\n",
    "            index_images = calculate_vegetation_index_from_xr_dataset(data, enum_index_type)\n",
    "        elif index_category == \"Fuego\":\n",
    "            enum_index_type = FireIndex[index_type]\n",
    "            index_images = calculate_fire_index_from_xr_dataset(data, enum_index_type)\n",
    "        elif index_category == \"Agua\":\n",
    "            enum_index_type = WaterIndex[index_type]\n",
    "            index_images = calculate_water_index_from_xr_dataset(data, enum_index_type)\n",
    "        else:\n",
    "            index_images = None\n",
    "            \n",
    "        index_images = np.nan_to_num(index_images) # Replace NaN with 0\n",
    "\n",
    "            \n",
    "        if index_images is not None:\n",
    "            vmin_all = np.min(index_images)\n",
    "            vmax_all = np.max(index_images)\n",
    "            # Actualizar y habilitar los widgets de umbral\n",
    "            threshold_a.min = vmin_all\n",
    "            threshold_a.max = vmax_all\n",
    "            threshold_a.value = vmin_all\n",
    "            threshold_a.disabled = False\n",
    "            \n",
    "            threshold_b.min = vmin_all\n",
    "            threshold_b.max = vmax_all\n",
    "            threshold_b.value = vmax_all\n",
    "            threshold_b.disabled = False\n",
    "        else:\n",
    "            # Deshabilitar los widgets de umbral si no hay imágenes de índice\n",
    "            threshold_a.disabled = True\n",
    "            threshold_b.disabled = True\n",
    "            \n",
    "    index_category_selector.observe(update_index_category, names='value')\n",
    "    index_type_selector.observe(update_index_type, names='value')\n",
    "    \n",
    "    if mask is not None:\n",
    "        mask3 = np.repeat(mask[:, :, np.newaxis], 3, axis=2)\n",
    "   \n",
    "    def plot_images(date_index, threshold_a, threshold_b, name = None):\n",
    "        \"\"\"\n",
    "        Dibuja un par de imágenes RGB e índice basado en el índice de fecha seleccionado.\n",
    "        \"\"\"        \n",
    "        nonlocal selected_date\n",
    "        selected_date.value = f\"Fecha seleccionada: {dates[date_index].strftime('%Y-%m-%d')}\"\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        \n",
    "        transposed_rgb = rgb_images[date_index].transpose((1, 2, 0))\n",
    "        transposed_rgb = transposed_rgb * mask3 if mask is not None else transposed_rgb\n",
    "        transposed_rgb = normalize_image_percentile(transposed_rgb)\n",
    "        \n",
    "        # Mostrar imagen RGB\n",
    "        ax1.imshow(transposed_rgb)\n",
    "        ax1.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} RGB')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        if index_images is not None:\n",
    "            index_img = index_images[date_index]\n",
    "            normed_img = (index_img - threshold_a) / (threshold_b - threshold_a)  # Normalize the data\n",
    "            my_cmap = matplotlib.colormaps['viridis']\n",
    "            colored_img = my_cmap(normed_img)\n",
    "            colored_img = colored_img[:, :, :3]\n",
    "\n",
    "            threshold_mask = (index_img > threshold_a) & (index_img < threshold_b)\n",
    "            threshold_mask3 = np.repeat(threshold_mask[:, :, np.newaxis], 3, axis=2)\n",
    "            \n",
    "            masked_img = colored_img * threshold_mask3  * mask3 if mask is not None else colored_img * threshold_mask3\n",
    "\n",
    "            # Mostrar imagen de índice\n",
    "            cax = ax2.imshow(masked_img, cmap='viridis', vmin=threshold_a, vmax=threshold_b)\n",
    "            if name is not None:\n",
    "                ax2.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} {name}')\n",
    "            else:\n",
    "                ax2.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} Índice')\n",
    "            ax2.axis('off')\n",
    "            cbar = plt.colorbar(cax, ax=ax2)\n",
    "            cbar.set_label('Valor del Índice', rotation=270, labelpad=20)\n",
    "        else:\n",
    "            ax2.imshow(np.zeros_like(transposed_rgb))\n",
    "            ax2.set_title(\"Índice no disponible\")\n",
    "            ax2.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    threshold_a = widgets.BoundedFloatText(\n",
    "        step=0.01,\n",
    "        description='Umbral A:',\n",
    "        disabled=True\n",
    "    )\n",
    "\n",
    "    threshold_b = widgets.BoundedFloatText(\n",
    "        step=0.01,\n",
    "        description='Umbral B:',\n",
    "        disabled=True\n",
    "    )\n",
    "    \n",
    "    # Create slider widget for date selection\n",
    "    date_slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(dates) - 1,\n",
    "        step=1,\n",
    "        description='Index:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "    date_slider.layout.width = '500px'\n",
    "    date_slider.index = dates\n",
    "    \n",
    "    # Create buttons for easier navigation\n",
    "    prev_button = widgets.Button(description=\"Previous\")\n",
    "    next_button = widgets.Button(description=\"Next\")\n",
    "    \n",
    "    def on_prev_button_clicked(b):\n",
    "        date_slider.value = max(0, date_slider.value - 1)\n",
    "\n",
    "    def on_next_button_clicked(b):\n",
    "        date_slider.value = min(len(dates) - 1, date_slider.value + 1)\n",
    "    \n",
    "   \n",
    "        \n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    \n",
    "    # Create a label to display the selected date\n",
    "    selected_date = widgets.Label(value=\"\")\n",
    "\n",
    "    navigation_box = widgets.HBox([prev_button, next_button])\n",
    "    index_selector_box = widgets.HBox([index_category_selector, index_type_selector])\n",
    "    threshold_box = widgets.HBox([threshold_a, threshold_b])\n",
    "\n",
    "\n",
    "    # Create the interactive plot\n",
    "    interactive_plot = widgets.interactive_output(plot_images, {'date_index': date_slider, 'threshold_a': threshold_a, 'threshold_b': threshold_b})\n",
    "    \n",
    "    # Show the widgets\n",
    "    display(widgets.VBox([navigation_box, selected_date, interactive_plot, date_slider, index_selector_box, threshold_box]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proccess_vegetation_index_from_xr_dataset(bands: xr.Dataset,\n",
    "                                    dates: list[datetime],\n",
    "                                    monitoring_start: datetime, \n",
    "                                    mask: np.ndarray, \n",
    "                                    input_path_folder: str,\n",
    "                                    output_folder: str, \n",
    "                                    normalize: bool, \n",
    "                                    vegetation_index: VegetationIndex = VegetationIndex.NDVI, \n",
    "                                    index_range_a: float = -1,\n",
    "                                    index_range_b: float = 1):\n",
    "    \n",
    "    visible_images = [(img / img.max()).astype(np.float32) for img in \n",
    "                  [bands.sel(time=time)[[\"red\", \"green\", \"blue\"]].to_array().values for time in bands.time.values]]\n",
    "    \n",
    "    vegetation_indexes = calculate_vegetation_index_from_xr_dataset(bands, vegetation_index) # Calculate vegetation index\n",
    "    vegetation_indexes = np.nan_to_num(vegetation_indexes) # Replace NaN with 0\n",
    "   \n",
    "    if index_range_a is not None and index_range_b is not None:\n",
    "        vegetation_indexes = np.clip(vegetation_indexes, index_range_a, index_range_b)\n",
    "    elif index_range_a is not None:\n",
    "        vegetation_indexes = np.clip(vegetation_indexes, index_range_a, np.max(vegetation_indexes))\n",
    "    elif index_range_b is not None:\n",
    "        vegetation_indexes = np.clip(vegetation_indexes, np.min(vegetation_indexes), index_range_b)\n",
    "\n",
    "    #aply mask to the fire indexes (xr DataArray) if mask not None if not in mask then 0\n",
    "    if mask is not None:\n",
    "        vegetation_indexes = [np.where(mask, index, 0) for index in vegetation_indexes]\n",
    "    \n",
    "    interactive_image_plotter_index(visible_images, vegetation_indexes, dates, mask, vegetation_index) # Plot images\n",
    "\n",
    "\n",
    "def proccess_fire_index_from_xr_dataset(bands: xr.Dataset,\n",
    "                                    dates: list[datetime],\n",
    "                                    monitoring_start: datetime, \n",
    "                                    mask: np.ndarray, \n",
    "                                    input_path_folder: str,\n",
    "                                    output_folder: str, \n",
    "                                    normalize: bool, \n",
    "                                    fire_index: FireIndex = FireIndex.NBR,\n",
    "                                    index_range_a: float = -1,\n",
    "                                    index_range_b: float = 1):\n",
    "    \n",
    "    visible_images = [(img / img.max()).astype(np.float32) for img in \n",
    "                  [bands.sel(time=time)[[\"red\", \"green\", \"blue\"]].to_array().values for time in bands.time.values]]\n",
    "    fire_indexes = calculate_fire_index_from_xr_dataset(bands, fire_index) # Calculate the fire index\n",
    "    fire_indexes = np.nan_to_num(fire_indexes) # Replace NaN with 0\n",
    "    print('Ranges for fire index are:')\n",
    "    print(f\"Valor mínimo: {index_range_a}\")\n",
    "    print(f\"Valor máximo: {index_range_b}\")\n",
    "    if index_range_a is not None and index_range_b is not None:\n",
    "        fire_indexes = np.clip(fire_indexes, index_range_a, index_range_b)\n",
    "    elif index_range_a is not None:\n",
    "        fire_indexes = np.clip(fire_indexes, index_range_a, np.max(fire_indexes))\n",
    "    elif index_range_b is not None:\n",
    "        fire_indexes = np.clip(fire_indexes, np.min(fire_indexes), index_range_b)\n",
    "\n",
    "    #aply mask to the fire indexes (xr DataArray) if mask not None if not in mask then 0\n",
    "    if mask is not None:\n",
    "        fire_indexes = [np.where(mask, index, 0) for index in fire_indexes]\n",
    "        \n",
    "    interactive_image_plotter_index(visible_images, fire_indexes, dates, mask, fire_index) # Plot images\n",
    "    \n",
    "def proccess_water_index_from_xr_dataset(bands: xr.Dataset,\n",
    "                                    dates: list[datetime],\n",
    "                                    monitoring_start: datetime, \n",
    "                                    mask: np.ndarray, \n",
    "                                    input_path_folder: str,\n",
    "                                    output_folder: str, \n",
    "                                    normalize: bool, \n",
    "                                    water_index: WaterIndex = WaterIndex.MNDWI,\n",
    "                                    index_range_a: float = -1,\n",
    "                                    index_range_b: float = 1):\n",
    "    \n",
    "    visible_images = [(img / img.max()).astype(np.float32) for img in \n",
    "                  [bands.sel(time=time)[[\"red\", \"green\", \"blue\"]].to_array().values for time in bands.time.values]]\n",
    "    water_indexes = calculate_water_index_from_xr_dataset(bands, water_index) # Calculate the fire index\n",
    "    water_indexes = np.nan_to_num(water_indexes) # Replace NaN with 0\n",
    "    \n",
    "    # range selection\n",
    "    if index_range_a is not None and index_range_b is not None:\n",
    "        water_indexes = np.clip(water_indexes, index_range_a, index_range_b)\n",
    "    elif index_range_a is not None:\n",
    "        water_indexes = np.clip(water_indexes, index_range_a, np.max(water_indexes))\n",
    "    elif index_range_b is not None:\n",
    "        water_indexes = np.clip(water_indexes, np.min(water_indexes), index_range_b)\n",
    "\n",
    "    #aply mask to the fire indexes (xr DataArray) if mask not None if not in mask then 0\n",
    "    if mask is not None:\n",
    "        water_indexes = [np.where(mask, index, 0) for index in water_indexes]\n",
    "        \n",
    "    \n",
    "        \n",
    "    interactive_image_plotter_index(visible_images, water_indexes, dates, mask, water_index) # Plot images\n",
    "    \n",
    "\n",
    "def proccess_index_from_xr_dataset(bands: xr.Dataset,\n",
    "                                    dates: list[datetime],\n",
    "                                    monitoring_start: datetime, \n",
    "                                    mask: np.ndarray, \n",
    "                                    input_path_folder: str,\n",
    "                                    output_folder: str, \n",
    "                                    normalize: bool):\n",
    "\n",
    "    interactive_image_plotter(bands, dates, mask) # Plot images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvl/tesis/.venv/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35401 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-4ae8ce4f-6e7a-11ee-8282-17aaaede58e3</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:35401/status\" target=\"_blank\">http://127.0.0.1:35401/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">97a8d36a</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:35401/status\" target=\"_blank\">http://127.0.0.1:35401/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 12\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 15.55 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-5bb340e7-0c6b-4d5d-9834-b324da0b5299</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:42741\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:35401/status\" target=\"_blank\">http://127.0.0.1:35401/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 12\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 15.55 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:32887\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:45773/status\" target=\"_blank\">http://127.0.0.1:45773/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.89 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:37591\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-8p2k968g\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:42777\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:40259/status\" target=\"_blank\">http://127.0.0.1:40259/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.89 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:35837\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-ofs1gtt8\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:36665\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:38801/status\" target=\"_blank\">http://127.0.0.1:38801/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.89 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:46045\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-in8fjftq\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:43123\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 3\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:39583/status\" target=\"_blank\">http://127.0.0.1:39583/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 3.89 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:37811\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-ih_ke6b5\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42741' processes=4 threads=12, memory=15.55 GiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pystac_client import Client\n",
    "from odc.stac import configure_rio, stac_load\n",
    "\n",
    "catalog = Client.open(\"https://earth-search.aws.element84.com/v1\")\n",
    "client = dask.distributed.Client()\n",
    "configure_rio(cloud_defaults=True, aws={\"aws_unsigned\": True}, client=client)\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the start date and end date from the user (year and month)\n",
    "#history_start  = datetime(2020, 1, 1)\n",
    "history_start  = datetime(2022, 1, 1)\n",
    "monitoring_start = datetime(2022, 12, 30)\n",
    "#history_end = datetime(2022, 10, 31)\n",
    "history_end = datetime(2023, 4, 30)\n",
    "ignore_ranges = []\n",
    "ignore_ranges.append([datetime(2022, 1, 30), datetime(2022, 2, 28)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "import importlib\n",
    "\n",
    "stac_cfg = {\n",
    "    'sentinel-2-l2a': {\n",
    "        'assets': {'*': {'data_type': 'uint16', 'nodata': 0}},\n",
    "    }\n",
    "}\n",
    "\n",
    "ndvi_thresholds = [None, -0.1, -0.01]\n",
    "rvi_thresholds = [None, -0.1, 0, 0.1, 0.25, 1]\n",
    "savi_thresholds = [None, -0.1, 0, 0.1, 1]\n",
    "arvi_thresholds = [None, -0.1, 0, 0.1, 1]\n",
    "bai_thresholds = [0.01, 0.1, 1]\n",
    "nbr_thresholds = [None, -0.1, 0]\n",
    "afi_thresholds = [None,-0.15]\n",
    "msrif_thresholds = [None, 0, None]\n",
    "#bands = ['coastal', 'blue', 'green', 'red', 'nir', 'nir08', 'nir09', 'rededge1', 'rededge2', 'rededge3', 'scl', 'swir16', 'swir22']\n",
    "bands = ['blue', 'green', 'red', 'nir', 'nir08', 'nir09', 'rededge1', 'rededge2', 'rededge3', 'scl', 'swir16', 'swir22']\n",
    "\n",
    "\n",
    "\n",
    "thresholds = {\n",
    "    'eo:cloud_cover': 20,\n",
    "    's2:medium_proba_clouds_percentage': 10,\n",
    "    's2:high_proba_clouds_percentage': 5,\n",
    "    's2:low_proba_clouds_percentage': 20,\n",
    "    's2:thin_cirrus_percentage': 10,\n",
    "    's2:cloud_shadow_percentage': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def process_region(zone, region, index_type=None, index_range_a = None, index_range_b = None):\n",
    "    input_path = make_dir([\"./data/input\", zone, region])\n",
    "    output_path = make_dir([\"./data/output\", zone, region])\n",
    "    polygon = zone_dict[zone][region][\"polygon\"]\n",
    "        \n",
    "    data, properties = fetch_or_cache_stac_data_by_band_and_month(catalog, \n",
    "                                                    collections=[\"sentinel-2-l2a\"],\n",
    "                                                    bands=bands,\n",
    "                                                    start_date=history_start.strftime(\"%Y-%m-%d\"),\n",
    "                                                    end_date= history_end.strftime(\"%Y-%m-%d\"), \n",
    "                                                    limit=1000,\n",
    "                                                    bbox=polygon.bounds,\n",
    "                                                    resolution=10,\n",
    "                                                    cloud_cover=100,\n",
    "                                                    stac_config=stac_cfg,\n",
    "                                                    #crs=\"EPSG:4326\",\n",
    "                                                    crs = \"EPSG:3857\",\n",
    "                                                    cache_dir=input_path,\n",
    "                                                    force_download=False,\n",
    "                                                    log_level= LogLevel.Info,)    \n",
    "    \n",
    "    mask, mask3 = get_kml_polygon_masks(polygon, data['red'].shape[2], data['red'].shape[1])\n",
    "        \n",
    "    data = data.sel(time=[t for t in data.time.values if all(t < np.datetime64(start) or t > np.datetime64(end) for start, end in ignore_ranges)])\n",
    "    xr_times = data['time'].values.astype(str).tolist()\n",
    "    properties = [d for d in properties if d['datetime'][:19] in {x[:19] for x in xr_times}]\n",
    "    \n",
    "    sunny_dates, cloudy_dates = classify_sunny_cloudy_dates_by_scene_classification(data, thresholds, mask)        \n",
    "    \n",
    "    # remove cloudy images\n",
    "    data = data.sel(time=[t for t in data.time.values if t in sunny_dates])\n",
    "    dates = [pd.Timestamp(date).to_pydatetime().replace(hour=0, minute=0, second=0, microsecond=0)  for date in data['time'].values]\n",
    "        \n",
    "    if index_type is None:\n",
    "        proccess_index_from_xr_dataset(data, dates, monitoring_start, mask, input_path, output_path, True)\n",
    "    else:\n",
    "        if index_type in [e.name for e in VegetationIndex]:\n",
    "            enum_index_type = VegetationIndex[index_type]\n",
    "            proccess_vegetation_index_from_xr_dataset(data, dates, monitoring_start, mask, input_path, output_path, True, enum_index_type, index_range_a, index_range_b)\n",
    "        elif index_type in [e.name for e in FireIndex]:\n",
    "            enum_index_type = FireIndex[index_type]\n",
    "            proccess_fire_index_from_xr_dataset(data, dates, monitoring_start, mask, input_path, output_path, True, enum_index_type, index_range_a, index_range_b)\n",
    "        elif index_type in [e.name for e in WaterIndex]:\n",
    "            enum_index_type = WaterIndex[index_type]\n",
    "            proccess_water_index_from_xr_dataset(data, dates, monitoring_start, mask, input_path, output_path, True, enum_index_type, index_range_a, index_range_b)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de6a55601744d8eb759106ae8bef50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Tipo de Índice:', options=('Vegetativo', 'Fuego', 'Agua'), value='Vegetativo')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feda492d70ec41f088b02362c816efed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Índice Específico:', options=('DVI', 'RVI', 'PVI', 'IPVI', 'WDVI', 'TNDVI', 'GNDVI', 'GE…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa4fb409b3049d786e667236b5e8447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Zone:', options=('Bosques Bio Bio', 'Incendios', 'Bosques Arauco'), value='Bosques Bio B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c92ef70ef84ad2b668652e892d0ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Region:', options=('Bosque 1', 'Bosque 2', 'Bosque 3'), value='Bosque 1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3259e3c10e48efbd1d22c6a6256e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Diccionarios para los índices\n",
    "index_categories = {\n",
    "    \"Vegetativo\": [e.name for e in VegetationIndex],\n",
    "    \"Fuego\": [e.name for e in FireIndex],\n",
    "    \"Agua\": [e.name for e in WaterIndex]\n",
    "}\n",
    "\n",
    "# Dropdown para Tipo de Índice\n",
    "type_selector = widgets.Dropdown(\n",
    "    options=[\"Vegetativo\", \"Fuego\", \"Agua\"],\n",
    "    description='Tipo de Índice:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Dropdown para Índice Específico\n",
    "index_selector = widgets.Dropdown(\n",
    "    options=index_categories[\"Vegetativo\"],\n",
    "    description='Índice Específico:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Actualizar opciones de índice cuando cambia el tipo de índice\n",
    "def update_indices(change):\n",
    "    index_selector.options = index_categories[change['new']]\n",
    "\n",
    "type_selector.observe(update_indices, names='value')\n",
    "\n",
    "\n",
    "zone_widget = widgets.Dropdown(\n",
    "    options=zone_dict.keys(),\n",
    "    description='Zone:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "region_widget = widgets.Dropdown(\n",
    "    options=zone_dict[zone_widget.value].keys(),\n",
    "    description='Region:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_region_options(change):\n",
    "    region_widget.options = zone_dict[change['new']].keys()\n",
    "\n",
    "zone_widget.observe(update_region_options, names='value')\n",
    "\n",
    "# Botón para procesar\n",
    "process_button = widgets.Button(description=\"Process\")\n",
    "\n",
    "# Función para manejar evento del botón\n",
    "def on_process_button_clicked(b):  \n",
    "    clear_output(wait=True)  # Limpiar la salida anterior\n",
    "    display(type_selector, index_selector, zone_widget, region_widget, process_button)  # Volver a mostrar los widgets\n",
    "    process_region(zone_widget.value, region_widget.value, index_selector.value)\n",
    "\n",
    "process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(type_selector, index_selector, zone_widget, region_widget, process_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72eb4f109d864014be65d1dbb76515a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Zone:', options=('Bosques Bio Bio', 'Incendios', 'Bosques Arauco'), value='Bosques Bio B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e074ddfd84478a149ae69da6b16bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Region:', options=('Bosque 1', 'Bosque 2', 'Bosque 3'), value='Bosque 1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23f5797e06b41e7a2bc4a5a1dde7127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea3e8f0b13540f69eaf17e79f955142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zone_widget = widgets.Dropdown(\n",
    "    options=zone_dict.keys(),\n",
    "    description='Zone:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "region_widget = widgets.Dropdown(\n",
    "    options=zone_dict[zone_widget.value].keys(),\n",
    "    description='Region:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_region_options(change):\n",
    "    region_widget.options = zone_dict[change['new']].keys()\n",
    "\n",
    "zone_widget.observe(update_region_options, names='value')\n",
    "\n",
    "# Botón para procesar\n",
    "process_button = widgets.Button(description=\"Process\")\n",
    "status_label = widgets.Label(value=\"\")\n",
    "\n",
    "# Función para manejar evento del botón\n",
    "def on_process_button_clicked(b):  \n",
    "    process_button.disabled = True\n",
    "    status_label.value = \"Procesando...\"\n",
    "    process_region(zone_widget.value, region_widget.value)\n",
    "    process_button.disabled = False\n",
    "    status_label.value = \"Procesamiento completado\"\n",
    "    \n",
    "process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(zone_widget, region_widget, process_button, status_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_by_zone(zone, region, only_sunny_dates = True):\n",
    "    input_path = make_dir([\"./data/input\", zone, region])\n",
    "    output_path = make_dir([\"./data/output\", zone, region])\n",
    "    polygon = zone_dict[zone][region][\"polygon\"]\n",
    "        \n",
    "    data, properties = fetch_or_cache_stac_data_by_band_and_month(catalog, \n",
    "                                                    collections=[\"sentinel-2-l2a\"],\n",
    "                                                    bands=bands,\n",
    "                                                    start_date=history_start.strftime(\"%Y-%m-%d\"),\n",
    "                                                    end_date= history_end.strftime(\"%Y-%m-%d\"), \n",
    "                                                    limit=1000,\n",
    "                                                    bbox=polygon.bounds,\n",
    "                                                    resolution=10,\n",
    "                                                    cloud_cover=100,\n",
    "                                                    stac_config=stac_cfg,\n",
    "                                                    #crs=\"EPSG:4326\",\n",
    "                                                    crs = \"EPSG:3857\",\n",
    "                                                    cache_dir=input_path,\n",
    "                                                    force_download=False,\n",
    "                                                    log_level= LogLevel.Info,)    \n",
    "    \n",
    "    #mask, mask3 = get_kml_polygon_masks(polygon, data['red'].shape[2], data['red'].shape[1])\n",
    "        \n",
    "    data = data.sel(time=[t for t in data.time.values if all(t < np.datetime64(start) or t > np.datetime64(end) for start, end in ignore_ranges)])\n",
    "    xr_times = data['time'].values.astype(str).tolist()\n",
    "    properties = [d for d in properties if d['datetime'][:19] in {x[:19] for x in xr_times}]\n",
    "    mask, mask3 = get_kml_polygon_masks(polygon, data['red'].shape[2], data['red'].shape[1])\n",
    "    if(only_sunny_dates):\n",
    "        sunny_dates, cloudy_dates = classify_sunny_cloudy_dates_by_scene_classification(data, thresholds, mask)        \n",
    "        data = data.sel(time=[t for t in data.time.values if t in sunny_dates])\n",
    "    \n",
    "    dates = [pd.Timestamp(date).to_pydatetime().replace(hour=0, minute=0, second=0, microsecond=0)  for date in data['time'].values]\n",
    "    return data, dates, polygon, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ComparisonType(Enum):\n",
    "    GREATER_THAN = \"greater_than\"\n",
    "    LESS_THAN = \"less_than\"\n",
    "\n",
    "class ImageMaskConfiguration:\n",
    "    def __init__(self, enable=False, index_category=0, index_type=0, comparison=ComparisonType.GREATER_THAN, threshold=0.0):\n",
    "        self._enable = enable\n",
    "        self._index_category = index_category\n",
    "        self._index_type = index_type\n",
    "        self._comparison = comparison\n",
    "        self._threshold = threshold\n",
    "        \n",
    "    @property\n",
    "    def enable(self):\n",
    "        \"\"\"Getter for enable attribute\"\"\"\n",
    "        return self._enable\n",
    "\n",
    "    @enable.setter\n",
    "    def enable(self, value):\n",
    "        \"\"\"Setter for enable attribute with basic validation\"\"\"\n",
    "        if isinstance(value, bool):\n",
    "            self._enable = value\n",
    "        else:\n",
    "            print(\"Enable should be a boolean value.\")\n",
    "        \n",
    "    @property\n",
    "    def index_category(self):\n",
    "        \"\"\"Getter for index_category attribute\"\"\"\n",
    "        return self._index_category\n",
    "\n",
    "    @index_category.setter\n",
    "    def index_category(self, value):\n",
    "        \"\"\"Setter for index_category attribute with basic validation\"\"\"\n",
    "        if isinstance(value, int):\n",
    "            self._index_category = value\n",
    "        else:\n",
    "            print(\"IndexType should be an integer.\")\n",
    "            \n",
    "    @property\n",
    "    def index_type(self):\n",
    "        \"\"\"Getter for index_type attribute\"\"\"\n",
    "        return self._index_type\n",
    "\n",
    "    @index_type.setter\n",
    "    def index_type(self, value):\n",
    "        \"\"\"Setter for index_type attribute with basic validation\"\"\"\n",
    "        if isinstance(value, int):\n",
    "            self._index_type = value\n",
    "        else:\n",
    "            print(\"IndexValue should be an integer.\")\n",
    "            \n",
    "    @property\n",
    "    def comparison(self):\n",
    "        \"\"\"Getter for comparison attribute\"\"\"\n",
    "        return self._comparison\n",
    "\n",
    "    @comparison.setter\n",
    "    def comparison(self, value):\n",
    "        \"\"\"Setter for comparison attribute with validation against Enum\"\"\"\n",
    "        if isinstance(value, ComparisonType):\n",
    "            self._comparison = value\n",
    "        else:\n",
    "            print(\"Invalid comparison. Please use a value from ComparisonType Enum.\")\n",
    "            \n",
    "    @property\n",
    "    def threshold(self):\n",
    "        \"\"\"Getter for threshold attribute\"\"\"\n",
    "        return self._threshold\n",
    "\n",
    "    @threshold.setter\n",
    "    def threshold(self, value):\n",
    "        \"\"\"Setter for threshold attribute with basic validation\"\"\"\n",
    "        if isinstance(value, float):\n",
    "            self._threshold = value\n",
    "        else:\n",
    "            print(\"Threshold should be a float.\")\n",
    "            \n",
    "    def print(self):\n",
    "        print(f\"Enable: {self.enable}\")\n",
    "        print(f\"IndexType: {self.index_category}\")\n",
    "        print(f\"IndexValue: {self.index_type}\")\n",
    "        print(f\"Comparison: {self.comparison}\")\n",
    "        print(f\"Threshold: {self.threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mask_image(data: xr.Dataset, date, image_mask_config: ImageMaskConfiguration):\n",
    "    \n",
    "    date_data = data.sel(time=date, method='nearest')\n",
    "    \n",
    "    if image_mask_config.enable:\n",
    "        index = None\n",
    "        if image_mask_config.index_category == IndexCategory.VEGETATION.value:\n",
    "            enum_index_type = VegetationIndex(list(VegetationIndex)[image_mask_config.index_type])\n",
    "            index = calculate_vegetation_index_from_xr_dataset(date_data, enum_index_type)\n",
    "        elif image_mask_config.index_category == IndexCategory.FIRE.value:\n",
    "            enum_index_type = FireIndex(list(FireIndex)[image_mask_config.index_type])\n",
    "            index = calculate_fire_index_from_xr_dataset(date_data, enum_index_type)\n",
    "        elif image_mask_config.index_category == IndexCategory.WATER.value:\n",
    "            enum_index_type = WaterIndex(list(WaterIndex)[image_mask_config.index_type])\n",
    "            index = calculate_water_index_from_xr_dataset(date_data, enum_index_type)\n",
    "        \n",
    "        if index is None:\n",
    "            raise ValueError(\"Index calculation failed or index type not recognized.\")\n",
    "\n",
    "        if image_mask_config.comparison == ComparisonType.GREATER_THAN:\n",
    "            mask_by_index = index > image_mask_config.threshold\n",
    "        else:\n",
    "            mask_by_index = index < image_mask_config.threshold\n",
    "        return mask_by_index, index\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def calculate_mask_difference_of_index_images(data: xr.Dataset, date, date_prev, image_mask_config: ImageMaskConfiguration):\n",
    "    date_data = data.sel(time=date, method='nearest')\n",
    "    date_prev_data = data.sel(time=date_prev, method='nearest')\n",
    "    \n",
    "    if image_mask_config.enable:\n",
    "        index = None\n",
    "        index_prev = None\n",
    "        \n",
    "        if image_mask_config.index_category == IndexCategory.VEGETATION.value:\n",
    "            enum_index_type = VegetationIndex(list(VegetationIndex)[image_mask_config.index_type])\n",
    "            index = calculate_vegetation_index_from_xr_dataset(date_data, enum_index_type)\n",
    "            index_prev = calculate_vegetation_index_from_xr_dataset(date_prev_data, enum_index_type)\n",
    "        elif image_mask_config.index_category == IndexCategory.FIRE.value:\n",
    "            enum_index_type = FireIndex(list(FireIndex)[image_mask_config.index_type])\n",
    "            index = calculate_fire_index_from_xr_dataset(date_data, enum_index_type)\n",
    "            index_prev = calculate_fire_index_from_xr_dataset(date_prev_data, enum_index_type)\n",
    "        elif image_mask_config.index_category == IndexCategory.WATER.value:\n",
    "            enum_index_type = WaterIndex(list(WaterIndex)[image_mask_config.index_type])\n",
    "            index = calculate_water_index_from_xr_dataset(date_data, enum_index_type)\n",
    "            index_prev = calculate_water_index_from_xr_dataset(date_prev_data, enum_index_type)\n",
    "        \n",
    "        if index is None or index_prev is None:\n",
    "            raise ValueError(\"Index calculation failed or index type not recognized.\")\n",
    "        \n",
    "        index_difference = index - index_prev\n",
    "        \n",
    "        if image_mask_config.comparison == ComparisonType.GREATER_THAN:\n",
    "            mask_by_index = index_difference > image_mask_config.threshold\n",
    "        else:\n",
    "            mask_by_index = index_difference < image_mask_config.threshold\n",
    "            \n",
    "        return mask_by_index, index_difference\n",
    "    else:\n",
    "        return None, None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.affinity import affine_transform\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import geopandas as gpd\n",
    "\n",
    "def get_transformation_matrix(polygon_bound, mask_shape):\n",
    "    \"\"\"\n",
    "    Calculate the transformation matrix based on the polygon_bound and mask_shape.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = polygon_bound.bounds  # Obtaining the bounds of the polygon\n",
    "    print(f\"Bounds: {minx}, {miny}, {maxx}, {maxy}\")\n",
    "    y_pixels, x_pixels = mask_shape\n",
    "    print(f\"Shape: {x_pixels}, {y_pixels}\")\n",
    "\n",
    "    x_scale = (maxx - minx) / x_pixels\n",
    "    y_scale = (maxy - miny) / y_pixels\n",
    "    print(f\"Scales: {x_scale}, {y_scale}\")\n",
    "\n",
    "    # Crear una matriz de transformación para convertir las coordenadas de píxeles a coordenadas geográficas\n",
    "    # [x_scale, 0, 0, y_scale, minx, miny]\n",
    "    transformation_matrix = [x_scale, 0, 0, -y_scale, minx, maxy]  \n",
    "\n",
    "    return transformation_matrix\n",
    "\n",
    "\n",
    "def get_polygons_from_mask(mask, label, polygon_bound, zone, region, type_index, date, ref_img_date = None, ref_filename = None):\n",
    "    \"\"\"\n",
    "    Convert a mask to a list of polygons with metadata.\n",
    "\n",
    "    Parameters:\n",
    "    mask (numpy array or xarray): A binary mask to convert to polygons.\n",
    "    polygon_bound (Polygon): The bounding polygon.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of transformed polygons.\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "\n",
    "    # Check if mask is an xarray, and if so, extract the numpy array\n",
    "    if hasattr(mask, 'values'):\n",
    "        mask_values = mask.values\n",
    "    else:\n",
    "        mask_values = mask\n",
    "\n",
    "    mask_values = np.transpose(mask_values)\n",
    "\n",
    "    contours = find_contours(mask_values, level=0.5)\n",
    "    transformation_matrix = get_transformation_matrix(polygon_bound, mask.shape)  # Define this function\n",
    "\n",
    "    for contour in contours:\n",
    "        # Convert contour coordinates to polygon\n",
    "        poly = Polygon(contour)\n",
    "\n",
    "        # Apply the transformation\n",
    "        poly_transformed = affine_transform(poly, transformation_matrix)\n",
    "        polygons.append({\n",
    "            'geometry': poly_transformed,\n",
    "        })\n",
    "\n",
    "    polygons = associate_holes(polygons)  # Function to classify polygons as 'outer' or 'hole'\n",
    "\n",
    "    for poly_data in polygons:\n",
    "        poly_data.update({\n",
    "            'zone': zone,\n",
    "            'region': region,\n",
    "            'type_index': type_index,\n",
    "            'date': date,  # Adding date here\n",
    "            'label': label,\n",
    "            'ref_filename': ref_filename\n",
    "        })\n",
    "        if ref_img_date is not None:\n",
    "            poly_data.update({\n",
    "                'ref_date': ref_img_date\n",
    "            })\n",
    "\n",
    "    return polygons\n",
    "\n",
    "def associate_holes(polygons):\n",
    "    \"\"\"\n",
    "    Associate holes with their corresponding outer polygons.\n",
    "    \"\"\"\n",
    "    associated_polygons_data = []\n",
    "    \n",
    "    for poly_data in polygons:\n",
    "        poly = poly_data['geometry']  # Accessing the polygon\n",
    "\n",
    "        # Identifying outer polygons\n",
    "        if not any(poly.within(p['geometry']) for p in polygons if p != poly_data):\n",
    "            # If it's an outer polygon, check for holes\n",
    "            holes = [p['geometry'] for p in polygons if p['geometry'].within(poly) and p != poly_data]\n",
    "            \n",
    "            # Create a new polygon with the identified holes\n",
    "            if holes:\n",
    "                holes_coords = [hole.exterior.coords[:] for hole in holes]\n",
    "                new_poly = Polygon(poly.exterior.coords[:], holes=holes_coords)\n",
    "            else:\n",
    "                new_poly = poly\n",
    "            \n",
    "            # Keep the metadata and update the geometry\n",
    "            new_poly_data = poly_data.copy()  # Copy the metadata\n",
    "            new_poly_data['geometry'] = new_poly  # Update the geometry\n",
    "            associated_polygons_data.append(new_poly_data)\n",
    "                \n",
    "    return associated_polygons_data\n",
    "\n",
    "\n",
    "def filter_polygons_by_size(polygons, min_size):\n",
    "    \"\"\"\n",
    "    Filter polygons by size.\n",
    "    \"\"\"\n",
    "    return [p for p in polygons if p.area >= min_size]\n",
    "\n",
    "\n",
    "def save_mask_image(label, zone, region, date, polygon, mask, type_index, output_path='./data/output', ref_img_date = None, tiff_filename = None):\n",
    "    \"\"\"\n",
    "    Save mask image as a shapefile containing various polygons.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Parameters: {zone}, {region}, {date}, {type_index}\")\n",
    "    \n",
    "    # Formatting the date to exclude time\n",
    "    formatted_date = date.strftime('%Y-%m-%d')\n",
    "    if ref_img_date is not None:\n",
    "        formatted_ref_img_date = ref_img_date.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        formatted_ref_img_date = None\n",
    "    \n",
    "    # Convert mask to polygons and get metadata\n",
    "    polygons_with_metadata = get_polygons_from_mask(mask, label, polygon, zone, region, type_index, formatted_date, formatted_ref_img_date, tiff_filename)\n",
    "\n",
    "    # Filter polygons by size\n",
    "    # valid_polygons = filter_polygons_by_size(polygons_with_metadata, min_size)\n",
    "    # Creating a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(polygons_with_metadata, crs='EPSG:4326')\n",
    "\n",
    "    # Creating the filename\n",
    "    filename = f\"{type_index}_{formatted_date}.shp\"\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    dir_path = f\"{output_path}/labels/{zone}/{region}/{label}\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Saving the GeoDataFrame as a Shapefile\n",
    "    filepath = f\"{output_path}/labels/{zone}/{region}/{label}/{filename}\"\n",
    "\n",
    "    gdf.to_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import label, sum\n",
    "\n",
    "def remove_small_objects(mask, min_size):\n",
    "    \"\"\"\n",
    "    Remove connected components that are smaller than min_size from the binary mask.\n",
    "    \n",
    "    Parameters:\n",
    "    mask (numpy.ndarray): binary mask where objects are represented by ones and zeros.\n",
    "    min_size (int): minimum size (number of pixels) that a connected component must have to be kept.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: a new binary mask with the small connected components removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Label each connected component in the mask\n",
    "    labeled_mask, num_labels = label(mask)\n",
    "    \n",
    "    # For each labeled object, calculate its size\n",
    "    sizes = sum(mask, labeled_mask, range(1, num_labels+1))\n",
    "    \n",
    "    # Create a new mask where small objects are removed\n",
    "    new_mask = np.zeros_like(mask)\n",
    "    removed = 0\n",
    "    kept = 0\n",
    "    for label_num, size in enumerate(sizes):\n",
    "        if size >= min_size:\n",
    "            new_mask[labeled_mask == label_num+1] = 1\n",
    "            kept += 1\n",
    "        else:\n",
    "            removed += 1\n",
    "            \n",
    "    return new_mask, kept, removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "import xarray as xr\n",
    "\n",
    "def save_tiff(dataset, date, output_path, base_filename, user_metadata):    \n",
    "\n",
    "    ds_selected = dataset.sel(time=date, method='nearest')\n",
    "    bands = [ds_selected[banda].values for banda in ds_selected.data_vars]\n",
    "\n",
    "    # Asumiendo que las coordenadas son latitud y longitud\n",
    "    lon_min, lat_min, lon_max, lat_max = ds_selected.longitude.min(), ds_selected.latitude.min(), ds_selected.longitude.max(), ds_selected.latitude.max()\n",
    "    \n",
    "    height, width = len(ds_selected.latitude), len(ds_selected.longitude)\n",
    "    \n",
    "    transform = from_bounds(west=lon_min, south=lat_min, east=lon_max, north=lat_max, width=width, height=height)\n",
    "    \n",
    "    output_filename = f\"{base_filename}_{date.strftime('%Y-%m-%d')}.tif\"\n",
    "    output_filepath = os.path.join(output_path, output_filename)\n",
    "    \n",
    "    metadata = {\n",
    "    'driver': 'GTiff',\n",
    "    'count': len(bands),  # número de bandas\n",
    "    'dtype': bands[0].dtype,  # asegúrate de que todas las bandas tengan el mismo dtype\n",
    "    'width': bands[0].shape[1],\n",
    "    'height': bands[0].shape[0],\n",
    "    'crs': 'EPSG:4326',  # o el CRS que estés utilizando,\n",
    "    'transform': transform\n",
    "    }\n",
    "    metadata['tags'] = user_metadata\n",
    "    metadata['date'] = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    \n",
    "    with rasterio.open(\n",
    "            output_filepath,\n",
    "            'w',\n",
    "            driver='GTiff',\n",
    "            **metadata\n",
    "    ) as dst:\n",
    "        for i, var_name in enumerate(ds_selected.data_vars):\n",
    "            dst.write(ds_selected[var_name].data, i+1)\n",
    "            dst.set_band_description(i+1, var_name)\n",
    "            \n",
    "    print(f\"File saved to: {output_filepath}\")\n",
    "    return output_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display\n",
    "import time\n",
    "def process_images_mask(zone, region, data, dates, polygon, properties, visible_images, num_index_to_process = 3, image_index = 0, prev_image_index = -1, labels = None):\n",
    "\n",
    "    number_inputs = []\n",
    "    mask, mask3 = get_kml_polygon_masks(polygon, data['red'].shape[2], data['red'].shape[1])\n",
    "    index_categories = {\n",
    "        \"Vegetativo\": [e.name for e in VegetationIndex],\n",
    "        \"Fuego\": [e.name for e in FireIndex],\n",
    "        \"Agua\": [e.name for e in WaterIndex]\n",
    "    }\n",
    "\n",
    "    radiobuttons = widgets.RadioButtons(\n",
    "        options=['Imagen individual', 'Calcular máscaras primero', 'Calcular máscaras después'],\n",
    "        description='Método:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    def on_change_radio_buttons(change):\n",
    "        if change['new'] == 'Imagen individual':\n",
    "            image_type_category.options = [\"Imagen final\"]\n",
    "            image_type_category.index = 0\n",
    "        if change['new'] == 'Calcular máscaras primero':\n",
    "            image_type_category.options = [\"Imagen final\", \"Imagen de referencia\", \"Diferencia\"]\n",
    "            image_type_category.index = 2\n",
    "        else:\n",
    "            image_type_category.options = [\"Imagen final\", \"Imagen de referencia\"]\n",
    "            image_type_category.index = 0\n",
    "                \n",
    "    radiobuttons.observe(on_change_radio_buttons, names='value')\n",
    "                \n",
    "    image_type_category = widgets.Dropdown(\n",
    "            options=[\"Imagen final\", \"Imagen de referencia\", \"Diferencia\"],\n",
    "            description='Imagen:',\n",
    "            disabled=False,\n",
    "        )\n",
    "    # Dropdown para seleccionar el color\n",
    "    color_dropdown = widgets.Dropdown(\n",
    "        options=['Red', 'Green', 'Blue', 'Orange', 'Yellow', 'Purple'],\n",
    "        value='Orange',\n",
    "        description='Color mascara:'\n",
    "    )\n",
    "\n",
    "    # Slider para seleccionar la transparencia (alpha)\n",
    "    alpha_slider = widgets.FloatSlider(\n",
    "        value=0.5,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='Transparencia:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "\n",
    "    configurations = [ImageMaskConfiguration() for _ in range(num_index_to_process)]\n",
    "    trigger_widget = widgets.Checkbox(value=False, layout=widgets.Layout(display='none'))\n",
    "\n",
    "    def on_value_change(change):\n",
    "        new_value = change['new']\n",
    "\n",
    "        if change['owner'].description == 'Habilitar':\n",
    "            config = change['owner'].config_ref\n",
    "            config.enable = new_value\n",
    "        elif change['owner'].description == 'Índice Específico':\n",
    "            config = change['owner'].config_ref\n",
    "            new_index = change['owner'].index \n",
    "            config.index_type = new_index\n",
    "        elif change['owner'].description == 'Comparación':\n",
    "            config = change['owner'].config_ref\n",
    "            comparison_mapping = {\n",
    "                \"Menor que\": ComparisonType.LESS_THAN,\n",
    "                \"Mayor que\": ComparisonType.GREATER_THAN\n",
    "            }\n",
    "            config.comparison = comparison_mapping.get(new_value, None)\n",
    "            if config.comparison is None:\n",
    "                print(f\"Invalid comparison value: {new_value}\")\n",
    "        elif change['owner'].description == 'Umbral':\n",
    "            config = change['owner'].config_ref\n",
    "            config.threshold = new_value\n",
    "            if change['owner'].manual_update == True:\n",
    "                return\n",
    "            \n",
    "        trigger_widget.value = not trigger_widget.value\n",
    "\n",
    "            \n",
    "    def create_widgets_for_configuration(config, on_value_change):\n",
    "        enable_widget = widgets.Checkbox(value=config.enable, description='Habilitar')\n",
    "        type_selector = widgets.Dropdown(options=[\"Vegetativo\", \"Fuego\", \"Agua\"], description='Tipo de Índice')\n",
    "        index_selector = widgets.Dropdown(options=index_categories[\"Vegetativo\"], description='Índice Específico')\n",
    "        comparison_selector = widgets.Dropdown(options=[\"Mayor que\", \"Menor que\"], description='Comparación')\n",
    "        number_input = widgets.BoundedFloatText(value=0, min=0, max=1000, step=0.1, description='Umbral')\n",
    "        \n",
    "        enable_widget.config_ref = config\n",
    "        type_selector.config_ref = config\n",
    "        index_selector.config_ref = config\n",
    "        comparison_selector.config_ref = config\n",
    "        number_input.config_ref = config\n",
    "        number_input.manual_update = False\n",
    "            \n",
    "        def update_indices(change):\n",
    "            index_selector.options = index_categories[change['new']]\n",
    "            config = change['owner'].config_ref\n",
    "            new_index = change['owner'].index  \n",
    "            config.index_category = new_index\n",
    "            \n",
    "        type_selector.observe(update_indices, names='value')\n",
    "        \n",
    "        def toggle_widgets(change):\n",
    "            state = change['new']\n",
    "            type_selector.disabled = not state\n",
    "            index_selector.disabled = not state\n",
    "            comparison_selector.disabled = not state\n",
    "            number_input.disabled = not state\n",
    "        \n",
    "        enable_widget.observe(toggle_widgets, names='value')\n",
    "\n",
    "        enable_widget.observe(on_value_change, names='value')\n",
    "        type_selector.observe(on_value_change, names='value')\n",
    "        index_selector.observe(on_value_change, names='value')\n",
    "        comparison_selector.observe(on_value_change, names='value')\n",
    "        number_input.observe(on_value_change, names='value')\n",
    "        number_inputs.append(number_input)\n",
    "        return [enable_widget, type_selector, index_selector, comparison_selector, number_input]\n",
    "    \n",
    "    color_dropdown.observe(on_value_change, names='value')\n",
    "    alpha_slider.observe(on_value_change, names='value')\n",
    "\n",
    "    PIXEL_AREA = 100  # 10m * 10m = 100m²\n",
    "    min_pixels = 500 / PIXEL_AREA  # Convert area to number of pixels\n",
    "    \n",
    "    \n",
    "    #Slider to select the minimum area (in m²) of the objects to keep\n",
    "    min_area_slider = widgets.IntSlider(\n",
    "        value=10,  # Initial value\n",
    "        min=0,  # Min value\n",
    "        max=1000,  # Max value\n",
    "        step=10,  # Step size\n",
    "        description='Min px:',  # Description or label for the slider\n",
    "        continuous_update=False  # Update only when the slider stops moving\n",
    "    )\n",
    "    \n",
    "    status_label = widgets.Label(value=\"\")\n",
    "\n",
    "    def update_threshold_range(position, min_value, max_value):\n",
    "        if(position <= len(number_inputs) - 1):\n",
    "            number_input = number_inputs[position]  # Accede al widget específico basado en la posición\n",
    "            number_input.manual_update = True  # Indica que el usuario cambió el valor\n",
    "            number_input.min = min_value  # Ajusta el valor min\n",
    "            number_input.max = max_value  # Ajusta el valor max\n",
    "            number_input.value = (min_value + max_value) / 2  # Ajusta el valor a la mitad del rango\n",
    "            time.sleep(0.1)  # Espera 0.1 segundos\n",
    "            number_input.manual_update = False  # Indica que el usuario no cambió el valor\n",
    "            \n",
    "    color_mapping = {\n",
    "            'Red': [1, 0, 0],\n",
    "            'Green': [0, 1, 0],\n",
    "            'Blue': [0, 0, 1],\n",
    "            'Orange': [1, 0.5, 0],\n",
    "            'Yellow': [1, 1, 0],\n",
    "            'Purple': [0.5, 0, 0.5]\n",
    "        }\n",
    "    \n",
    "    previous_trigger = None\n",
    "    mask_image = None\n",
    "    mask_prev_image = None\n",
    "    mask_diff = None\n",
    "    mask_calculated = False\n",
    "    mask_final = None\n",
    "    image_date = None \n",
    "    image_type_index = 0\n",
    "    objects_kept = 0\n",
    "    objects_removed = 0\n",
    "    def plot_image_mask(trigger, image_type, min_area, radio_button_value):\n",
    "        combined_mask = None\n",
    "        nonlocal previous_trigger, mask_calculated, mask_image, mask_prev_image, mask_diff, image_date, image_type_index, mask_final, objects_kept, objects_removed\n",
    "        print(radio_button_value)\n",
    "        if previous_trigger is None or trigger != previous_trigger:\n",
    "            mask_calculated = False\n",
    "            mask_image = None\n",
    "            mask_prev_image = None\n",
    "            mask_diff = None\n",
    "            previous_trigger = trigger\n",
    "                 \n",
    "        image_type_index = image_type_category.options.index(image_type)\n",
    "\n",
    "        if(radio_button_value == 'Imagen individual'):\n",
    "            if mask_calculated == False:\n",
    "                image_date = dates[image_index]\n",
    "                for i, config in enumerate(configurations):\n",
    "                    if config.enable == True:\n",
    "                        mask_index, image_for_index = calculate_mask_image(data, image_date, config)\n",
    "                        mask_index = np.logical_and(mask == 1, mask_index == 1)\n",
    "                        max_index_img = image_for_index.max().item()\n",
    "                        min_index_img = image_for_index.min().item()\n",
    "                        update_threshold_range(i, min_index_img, max_index_img)  \n",
    "                        mask_image = mask_index if mask_image is None else mask_image * mask_index\n",
    "            img_index = image_index\n",
    "            img_mask = mask_image\n",
    "        elif(radio_button_value == 'Calcular máscaras primero'):   \n",
    "            if mask_calculated == False:\n",
    "                image_date = dates[image_index]\n",
    "                prev_image_date = dates[prev_image_index]\n",
    "\n",
    "                for i, config in enumerate(configurations):\n",
    "                    if(config.enable):\n",
    "                        mask_index, image_for_index = calculate_mask_image(data, image_date, config)                \n",
    "                        mask_index = np.logical_and(mask == 1, mask_index == 1)\n",
    "                        max_index_img = image_for_index.max().item()\n",
    "                        min_index_img = image_for_index.min().item()\n",
    "                        update_threshold_range(i, min_index_img, max_index_img)  \n",
    "                        mask_image = mask_index if mask_image is None else mask_image * mask_index\n",
    "      \n",
    "                for i, config in enumerate(configurations):\n",
    "                    if(config.enable):\n",
    "                        mask_index, image_for_index = calculate_mask_image(data, prev_image_date, config)\n",
    "                        mask_index = np.logical_and(mask == 1, mask_index == 1)\n",
    "                        mask_prev_image = mask_index if mask_prev_image is None else mask_prev_image * mask_index\n",
    "                        mask_diff = mask_image ^ mask_prev_image\n",
    "            if(image_type_index == 0):\n",
    "                img_index = image_index\n",
    "                img_mask = mask_image\n",
    "            elif(image_type_index == 1):\n",
    "                img_index = prev_image_index\n",
    "                img_mask = mask_prev_image\n",
    "            else:\n",
    "                img_index = image_index\n",
    "                img_mask = mask_diff\n",
    "        else:\n",
    "            if mask_calculated == False:\n",
    "                image_date = dates[image_index]\n",
    "                prev_image_date = dates[prev_image_index]\n",
    "                \n",
    "                for i, config in enumerate(configurations):\n",
    "                    if(config.enable):\n",
    "                        mask_index, image_for_index = calculate_mask_difference_of_index_images(data, image_date, prev_image_date, config)\n",
    "                        mask_index = np.logical_and(mask == 1, mask_index == 1)\n",
    "                        max_index_img = image_for_index.max().item()\n",
    "                        min_index_img = image_for_index.min().item()\n",
    "                        update_threshold_range(i, min_index_img, max_index_img)  \n",
    "                        mask_diff = mask_index if mask_diff is None else mask_diff * mask_index\n",
    "        \n",
    "            if(image_type_index == 0):\n",
    "                img_index = image_index\n",
    "                img_mask = mask_diff\n",
    "            elif(image_type_index == 1):\n",
    "                img_index = prev_image_index\n",
    "                img_mask = mask_diff\n",
    "            \n",
    "        if img_mask is not None:\n",
    "            combined_mask = np.logical_and(mask == 1, img_mask == 1)\n",
    "        \n",
    "        transposed_rgb = visible_images[img_index].transpose((1, 2, 0))\n",
    "        transposed_rgb = transposed_rgb * mask3 if mask is not None else transposed_rgb\n",
    "        transposed_rgb = normalize_image_percentile(transposed_rgb)\n",
    "              \n",
    "        #show image\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        ax.imshow(transposed_rgb)\n",
    "        \n",
    "        if(combined_mask is not None):\n",
    "            mask_final, objects_kept, objects_removed = remove_small_objects(combined_mask, min_area)\n",
    "        else:\n",
    "            mask_final = None\n",
    "            objects_kept = 0\n",
    "            objects_removed = 0\n",
    "            \n",
    "        status_label.value = f\"Objetos removidos: {objects_removed} | Objetos mantenidos: {objects_kept}\"\n",
    "        \n",
    "        if mask_final is not None:\n",
    "            selected_color = color_mapping[color_dropdown.value] + [alpha_slider.value]\n",
    "            color_mask = np.zeros((mask_final.shape[0], mask_final.shape[1], 4))\n",
    "            color_mask[mask_final == 1] = selected_color  # Aplicar color solo donde mask es 1\n",
    "            ax.imshow(color_mask)\n",
    "        \n",
    "        ax.set_title(f'{dates[img_index].strftime(\"%Y-%m-%d\")} RGB')\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    labels_dropdown = widgets.Dropdown(\n",
    "        options=labels,\n",
    "        description='Etiqueta:',\n",
    "        disabled=False,\n",
    "    )\n",
    "     \n",
    "    interactive_plot_image = widgets.interactive_output(plot_image_mask, {'trigger': trigger_widget, 'image_type': image_type_category, 'min_area': min_area_slider, 'radio_button_value': radiobuttons})\n",
    "    \n",
    "    def on_button_process_clicked(b):\n",
    "        if mask_final is not None:\n",
    "            tiff_output_dir = './data/output/labels/tiff'\n",
    "            tiff_filename = f\"{zone}_{region}\"\n",
    "            user_properties = {\n",
    "                'zone': zone,\n",
    "                'region': region,\n",
    "            }\n",
    "            tiff_output_filepath = save_tiff(data, dates[image_index], tiff_output_dir, tiff_filename, user_properties)\n",
    "            save_mask_image(labels_dropdown.value, zone, region, dates[prev_image_index] if image_type_index == 1 else image_date, polygon, mask_final, labels_dropdown.index, './data/output',  dates[prev_image_index] if image_type_index == 2 else None)\n",
    "        else:\n",
    "            print(\"No hay máscara para guardar.\")\n",
    "    \n",
    "    button_process = widgets.Button(description=\"Guardar Shapefile\")\n",
    "    button_process.on_click(on_button_process_clicked)\n",
    "    \n",
    "    display(widgets.HBox([image_type_category, color_dropdown, alpha_slider]), widgets.HBox([radiobuttons, min_area_slider, status_label]))\n",
    "\n",
    "    # Mostrar widgets\n",
    "    for config in configurations:\n",
    "        widgets_list = create_widgets_for_configuration(config, on_value_change)\n",
    "        display(widgets.HBox(widgets_list))\n",
    "    \n",
    "    display(interactive_plot_image)\n",
    "    display(widgets.HBox([labels_dropdown, button_process]))  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images_widget(zone, region, only_sunny_dates = True, labels = None):\n",
    "    data, dates, polygon, properties = get_images_by_zone(zone, region, only_sunny_dates)\n",
    "    visible_images = [(img / img.max()).astype(np.float32) for img in \n",
    "                  [data.sel(time=time)[[\"red\", \"green\", \"blue\"]].to_array().values for time in data.time.values]]\n",
    "    mask, mask3 = get_kml_polygon_masks(polygon, data['red'].shape[2], data['red'].shape[1])\n",
    "    \n",
    "    date_slider_image = widgets.IntSlider(\n",
    "        value=1,\n",
    "        min=1,\n",
    "        max=len(dates) - 1,\n",
    "        step=1,\n",
    "        description='Imagen:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "    date_slider_image.layout.width = '450px'\n",
    "    date_slider_image.index = dates\n",
    "    \n",
    "    def on_date_slider_image_change(change):\n",
    "        date_slider_ref_image.value = min(date_slider_ref_image.value, date_slider_image.value - 1)\n",
    "        \n",
    "    date_slider_image.observe(on_date_slider_image_change, names='value')\n",
    "    \n",
    "    # Create buttons for easier navigation\n",
    "    prev_image_button = widgets.Button(description=\"Previa\")\n",
    "    next_image_button = widgets.Button(description=\"Siguiente\")\n",
    "\n",
    "    date_slider_ref_image = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(dates) - 2,\n",
    "        step=1,\n",
    "        description='Referencia:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "    date_slider_ref_image.layout.width = '450px'\n",
    "    date_slider_ref_image.index = dates\n",
    "    \n",
    "    def on_date_slider_ref_image_change(change):\n",
    "        date_slider_image.value = max(date_slider_image.value, date_slider_ref_image.value + 1)\n",
    "    \n",
    "    date_slider_ref_image.observe(on_date_slider_ref_image_change, names='value')\n",
    "    \n",
    "    # Create buttons for easier navigation\n",
    "    prev_ref_image_button = widgets.Button(description=\"Previa\")\n",
    "    next_ref_image_button = widgets.Button(description=\"Siguiente\")\n",
    "        \n",
    "    process_button = widgets.Button(description=\"Seleccionar\")   \n",
    "    \n",
    "    def on_prev_image_button_clicked(b):\n",
    "        date_slider_image.value = max(date_slider_image.min, date_slider_image.value - 1)\n",
    "    \n",
    "    def on_next_image_button_clicked(b):\n",
    "        date_slider_image.value = min(date_slider_image.max, date_slider_image.value + 1)\n",
    "        \n",
    "    def on_prev_ref_image_button_clicked(b):\n",
    "        date_slider_ref_image.value = max(date_slider_ref_image.min, date_slider_ref_image.value - 1)\n",
    "    \n",
    "    def on_next_ref_image_button_clicked(b):\n",
    "        date_slider_ref_image.value = min(date_slider_ref_image.max, date_slider_ref_image.value + 1)\n",
    "    \n",
    "    def plot_image(date_index):\n",
    "        transposed_rgb = visible_images[date_index].transpose((1, 2, 0))\n",
    "        transposed_rgb = transposed_rgb * mask3 if mask is not None else transposed_rgb\n",
    "        transposed_rgb = normalize_image_percentile(transposed_rgb)\n",
    "        \n",
    "        #show image\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        ax.imshow(transposed_rgb)\n",
    "        ax.set_title(f'{dates[date_index].strftime(\"%Y-%m-%d\")} RGB')\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    interactive_plot_image = widgets.interactive_output(plot_image, {'date_index': date_slider_image})\n",
    "    interactive_plot_ref_image = widgets.interactive_output(plot_image, {'date_index': date_slider_ref_image})\n",
    "    \n",
    "    prev_image_button.on_click(on_prev_image_button_clicked)\n",
    "    next_image_button.on_click(on_next_image_button_clicked)\n",
    "    prev_ref_image_button.on_click(on_prev_ref_image_button_clicked)\n",
    "    next_ref_image_button.on_click(on_next_ref_image_button_clicked)\n",
    "\n",
    "    def on_process_button_clicked(b):\n",
    "        process_button.disabled = True\n",
    "        clear_output(wait=True)\n",
    "        display(widgets.HBox([ \n",
    "            widgets.VBox([\n",
    "                widgets.HBox([date_slider_ref_image, prev_ref_image_button, next_ref_image_button]),\n",
    "                interactive_plot_ref_image\n",
    "                ])\n",
    "            ,\n",
    "            widgets.VBox([\n",
    "                widgets.HBox([date_slider_image, prev_image_button, next_image_button]),\n",
    "                interactive_plot_image\n",
    "            ])\n",
    "        ]),\n",
    "        process_button)\n",
    "        process_images_mask(zone, region, data, dates, polygon, properties, visible_images, 3, date_slider_image.value, date_slider_ref_image.value, labels)\n",
    "        process_button.disabled = False\n",
    "      \n",
    "    process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "    display(widgets.HBox([ \n",
    "        widgets.VBox([\n",
    "            widgets.HBox([date_slider_ref_image, prev_ref_image_button, next_ref_image_button]),\n",
    "            interactive_plot_ref_image\n",
    "            ])\n",
    "        ,\n",
    "        widgets.VBox([\n",
    "            widgets.HBox([date_slider_image, prev_image_button, next_image_button]),\n",
    "            interactive_plot_image\n",
    "        ])\n",
    "    ]),\n",
    "    process_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "def select_region_widget(select_callback, labels):\n",
    "    zone_widget = widgets.Dropdown(\n",
    "        options=zone_dict.keys(),\n",
    "        description='Zone:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    region_widget = widgets.Dropdown(\n",
    "        options=zone_dict[zone_widget.value].keys(),\n",
    "        description='Region:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    def update_region_options(change):\n",
    "        region_widget.options = zone_dict[change['new']].keys()\n",
    "\n",
    "    zone_widget.observe(update_region_options, names='value')\n",
    "\n",
    "    only_sunny_dates = widgets.Checkbox(value=True, description='Descartar imágenes con nubes')\n",
    "\n",
    "    # Botón para procesar\n",
    "    process_button = widgets.Button(description=\"Process\")\n",
    "    clear_button = widgets.Button(description=\"Clear\")\n",
    "    status_label = widgets.Label(value=\"\")\n",
    "\n",
    "    # Función para manejar evento del botón\n",
    "    def on_process_button_clicked(b):  \n",
    "        process_button.disabled = True\n",
    "        zone_widget.disabled = True\n",
    "        region_widget.disabled = True\n",
    "        only_sunny_dates.disabled = True\n",
    "        status_label.value = \"Procesando...\"\n",
    "        select_callback(zone_widget.value, region_widget.value, only_sunny_dates.value, labels)\n",
    "        status_label.value = \"Procesamiento completado\"\n",
    "        clear_button.disabled = False\n",
    "        \n",
    "    process_button.on_click(on_process_button_clicked)\n",
    "    \n",
    "    def display_region_widget(clear_output_request = False):\n",
    "        if clear_output_request:\n",
    "            clear_output(wait=True)\n",
    "        process_button.disabled = False\n",
    "        zone_widget.disabled = False\n",
    "        region_widget.disabled = False\n",
    "        only_sunny_dates.disabled = False\n",
    "        clear_button.disabled = True\n",
    "        status_label.value = \"\"\n",
    "        display(widgets.HBox([zone_widget, region_widget, only_sunny_dates]), widgets.HBox([process_button, clear_button]), status_label)\n",
    "    \n",
    "    \n",
    "    def on_clear_button_clicked(b):\n",
    "        display_region_widget(True)\n",
    "        \n",
    "    clear_button.on_click(on_clear_button_clicked)\n",
    "    \n",
    "    # Show widgets\n",
    "    display_region_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089bbfc2e1f74848b70b409de959c909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(IntSlider(value=0, continuous_update=False, description='Referenc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd2775c360946aababf0ab2e1fe113f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Seleccionar', disabled=True, style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab5834162b94769934569795e411846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Imagen:', options=('Imagen final', 'Imagen de referencia', 'Diferencia'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ed0a7818ee4d97b8bd76f212b88741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RadioButtons(description='Método:', options=('Imagen individual', 'Calcular máscaras primero', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a5328c29aa4b62881738227ed45f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='Habilitar'), Dropdown(description='Tipo de Índice', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87e3e266da544e6af87088e0015f96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='Habilitar'), Dropdown(description='Tipo de Índice', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c836a0a7074932adca69f12ec179b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='Habilitar'), Dropdown(description='Tipo de Índice', options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1407dea83324d2cbacd7f6de91d5a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b51518f9b724a0ea3efba638fb57325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Etiqueta:', options=('Talado', 'Incendio', 'Inundacion', 'Bosque', 'Otra …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19 09:23:40 - No hay máscara para guardar.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"not all values found in index 'time'. Try setting the `method` keyword argument (example: method='nearest').\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:581\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1642896000000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:549\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-01-23 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/core/indexes/datetimes.py:584\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     \u001b[39mreturn\u001b[39;00m Index\u001b[39m.\u001b[39;49mget_loc(\u001b[39mself\u001b[39;49m, key)\n\u001b[1;32m    585\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2022-01-23 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/xarray/core/indexes.py:769\u001b[0m, in \u001b[0;36mPandasIndex.sel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label_value)\n\u001b[1;32m    770\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/pandas/core/indexes/datetimes.py:586\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 586\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(orig_key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: datetime.datetime(2022, 1, 23, 0, 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/jvl/tesis/EDA_training_set.ipynb Cell 44\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=289'>290</a>\u001b[0m     tiff_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mzone\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mregion\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=290'>291</a>\u001b[0m     user_properties \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=291'>292</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mzone\u001b[39m\u001b[39m'\u001b[39m: zone,\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=292'>293</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mregion\u001b[39m\u001b[39m'\u001b[39m: region,\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=293'>294</a>\u001b[0m     }\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=294'>295</a>\u001b[0m     tiff_output_filepath \u001b[39m=\u001b[39m save_tiff(data, dates[image_index], tiff_output_dir, tiff_filename, user_properties)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=295'>296</a>\u001b[0m     save_mask_image(labels_dropdown\u001b[39m.\u001b[39mvalue, zone, region, dates[prev_image_index] \u001b[39mif\u001b[39;00m image_type_index \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m image_date, polygon, mask_final, labels_dropdown\u001b[39m.\u001b[39mindex, \u001b[39m'\u001b[39m\u001b[39m./data/output\u001b[39m\u001b[39m'\u001b[39m,  dates[prev_image_index] \u001b[39mif\u001b[39;00m image_type_index \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=296'>297</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m/home/jvl/tesis/EDA_training_set.ipynb Cell 44\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_tiff\u001b[39m(dataset, date, output_path, base_filename, user_metadata):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     ds_selected \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49msel(time\u001b[39m=\u001b[39;49mdate)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     bands \u001b[39m=\u001b[39m [ds_selected[banda]\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m banda \u001b[39min\u001b[39;00m ds_selected\u001b[39m.\u001b[39mdata_vars]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesis/EDA_training_set.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Asumiendo que las coordenadas son latitud y longitud\u001b[39;00m\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/xarray/core/dataset.py:3020\u001b[0m, in \u001b[0;36mDataset.sel\u001b[0;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a new dataset with each array indexed by tick labels\u001b[39;00m\n\u001b[1;32m   2960\u001b[0m \u001b[39malong the specified dimension(s).\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[39mDataArray.sel\u001b[39;00m\n\u001b[1;32m   3018\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3019\u001b[0m indexers \u001b[39m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[39m\"\u001b[39m\u001b[39msel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 3020\u001b[0m query_results \u001b[39m=\u001b[39m map_index_queries(\n\u001b[1;32m   3021\u001b[0m     \u001b[39mself\u001b[39;49m, indexers\u001b[39m=\u001b[39;49mindexers, method\u001b[39m=\u001b[39;49mmethod, tolerance\u001b[39m=\u001b[39;49mtolerance\n\u001b[1;32m   3022\u001b[0m )\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m drop:\n\u001b[1;32m   3025\u001b[0m     no_scalar_variables \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/xarray/core/indexing.py:190\u001b[0m, in \u001b[0;36mmap_index_queries\u001b[0;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         results\u001b[39m.\u001b[39mappend(IndexSelResult(labels))\n\u001b[1;32m    189\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         results\u001b[39m.\u001b[39mappend(index\u001b[39m.\u001b[39;49msel(labels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions))\n\u001b[1;32m    192\u001b[0m merged \u001b[39m=\u001b[39m merge_sel_results(results)\n\u001b[1;32m    194\u001b[0m \u001b[39m# drop dimension coordinates found in dimension indexers\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# (also drop multi-index if any)\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# (.sel() already ensures alignment)\u001b[39;00m\n",
      "File \u001b[0;32m~/tesis/.venv/lib/python3.10/site-packages/xarray/core/indexes.py:771\u001b[0m, in \u001b[0;36mPandasIndex.sel\u001b[0;34m(self, labels, method, tolerance)\u001b[0m\n\u001b[1;32m    769\u001b[0m                 indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(label_value)\n\u001b[1;32m    770\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 771\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    772\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnot all values found in index \u001b[39m\u001b[39m{\u001b[39;00mcoord_name\u001b[39m!r}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    773\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mTry setting the `method` keyword argument (example: method=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    774\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[39melif\u001b[39;00m label_array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    777\u001b[0m     indexer \u001b[39m=\u001b[39m label_array\n",
      "\u001b[0;31mKeyError\u001b[0m: \"not all values found in index 'time'. Try setting the `method` keyword argument (example: method='nearest').\""
     ]
    }
   ],
   "source": [
    "labels = ['Talado', 'Incendio', 'Inundacion', 'Bosque', 'Otra vegetacion', 'Plaga']\n",
    "select_region_widget(select_images_widget, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def process_region_mask(zone, region, image, num_index_to_process = 3, prev_image = None, comparison = False):\n",
    "    lines = []  # Lista para almacenar las referencias a los widgets de cada línea\n",
    "\n",
    "    index_categories = {\n",
    "        \"Vegetativo\": [e.name for e in VegetationIndex],\n",
    "        \"Fuego\": [e.name for e in FireIndex],\n",
    "        \"Agua\": [e.name for e in WaterIndex]\n",
    "    }\n",
    "\n",
    "    def create_line():\n",
    "        enable_widget = widgets.Checkbox(value=True, description='Habilitar')\n",
    "        \n",
    "        type_selector = widgets.Dropdown(options=[\"Vegetativo\", \"Fuego\", \"Agua\"], description='Tipo de Índice:')\n",
    "        index_selector = widgets.Dropdown(options=index_categories[\"Vegetativo\"], description='Índice Específico:')\n",
    "        comparison_selector = widgets.Dropdown(options=[\"Mayor que\", \"Menor que\"], description='Comparación:')\n",
    "        number_input = widgets.BoundedFloatText(value=0, min=0, max=1000, step=0.1, description='Número:')\n",
    "        \n",
    "        def update_indices(change):\n",
    "            index_selector.options = index_categories[change['new']]\n",
    "            \n",
    "        type_selector.observe(update_indices, names='value')\n",
    "        \n",
    "        def toggle_widgets(change):\n",
    "            state = change['new']\n",
    "            type_selector.disabled = not state\n",
    "            index_selector.disabled = not state\n",
    "            comparison_selector.disabled = not state\n",
    "            number_input.disabled = not state\n",
    "        \n",
    "        enable_widget.observe(toggle_widgets, names='value')\n",
    "        \n",
    "        def on_value_change(change):\n",
    "            line_index = lines.index(line_widgets)\n",
    "            print(f\"Valor cambiado en la línea {line_index+1}: {change['owner'].description} ahora es {change['new']}\")\n",
    "\n",
    "        enable_widget.observe(on_value_change, names='value')\n",
    "        type_selector.observe(on_value_change, names='value')\n",
    "        index_selector.observe(on_value_change, names='value')\n",
    "        comparison_selector.observe(on_value_change, names='value')\n",
    "        number_input.observe(on_value_change, names='value')\n",
    "        \n",
    "        line_widgets = {\n",
    "            \"enable\": enable_widget,\n",
    "            \"type_selector\": type_selector,\n",
    "            \"index_selector\": index_selector,\n",
    "            \"comparison_selector\": comparison_selector,\n",
    "            \"number_input\": number_input\n",
    "        }\n",
    "        \n",
    "        lines.append(line_widgets)\n",
    "        \n",
    "        return widgets.HBox([enable_widget, type_selector, index_selector, comparison_selector, number_input])\n",
    "\n",
    "    # Botón para procesar\n",
    "    process_button = widgets.Button(description=\"Procesar\")\n",
    "    process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "    # Botón para guardar\n",
    "    save_button = widgets.Button(description=\"Guardar Máscara\")\n",
    "\n",
    "    # Función para manejar evento del botón de procesar\n",
    "    def on_process_button_clicked(b):  \n",
    "        for line in lines:\n",
    "            if line[\"enable\"].value:  \n",
    "                # Puedes procesar cada línea de widgets aquí como lo necesites\n",
    "                \n",
    "                print(f\"Procesando línea con tipo de índice: {line['type_selector'].value}\")\n",
    "\n",
    "    # Función para manejar evento del botón de guardar\n",
    "    def on_save_button_clicked(b):  \n",
    "        print(\"Guardando máscara...\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "    # Mostrar widgets\n",
    "    display(process_button, save_button)\n",
    "    for _ in range(3):\n",
    "        display(create_line())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6300821c2864d5c9795c07158fbffc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Zone:', options=('Bosques Bio Bio', 'Incendios', 'Bosques Arauco'), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed514a44669f45c59bc7b80b29641580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19 09:25:53 - \u001b[33mUnique dates with NaN values across all bands: []\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cb739c53c04a74afcd7bb689937ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Previous', style=ButtonStyle()), Button(description='Next', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zone_widget = widgets.Dropdown(\n",
    "    options=zone_dict.keys(),\n",
    "    description='Zone:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "region_widget = widgets.Dropdown(\n",
    "    options=zone_dict[zone_widget.value].keys(),\n",
    "    description='Region:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_region_options(change):\n",
    "    region_widget.options = zone_dict[change['new']].keys()\n",
    "\n",
    "zone_widget.observe(update_region_options, names='value')\n",
    "\n",
    "# Botón para procesar\n",
    "process_button = widgets.Button(description=\"Process\")\n",
    "status_label = widgets.Label(value=\"\")\n",
    "\n",
    "# Función para manejar evento del botón\n",
    "def on_process_button_clicked(b):  \n",
    "    process_button.disabled = True\n",
    "    status_label.value = \"Procesando...\"\n",
    "    process_region(zone_widget.value, region_widget.value)\n",
    "    process_button.disabled = False\n",
    "    status_label.value = \"Procesamiento completado\"\n",
    "    \n",
    "process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(widgets.HBox([zone_widget, region_widget, process_button]), status_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tesina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

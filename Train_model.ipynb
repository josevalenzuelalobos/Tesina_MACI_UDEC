{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import shutil\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "def reproject_tiffs(input_folder, output_folder, new_crs='EPSG:4326'):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.tif') or filename.endswith('.tiff'):\n",
    "            \n",
    "            input_filepath = os.path.join(input_folder, filename)\n",
    "            output_filepath = os.path.join(output_folder, filename)\n",
    "            \n",
    "            with rasterio.open(input_filepath) as src:\n",
    "                transform, width, height = calculate_default_transform(\n",
    "                    src.crs, new_crs, src.width, src.height, *src.bounds)\n",
    "                kwargs = src.meta.copy()\n",
    "                kwargs.update({\n",
    "                    'crs': new_crs,\n",
    "                    'transform': transform,\n",
    "                    'width': width,\n",
    "                    'height': height\n",
    "                })\n",
    "                \n",
    "                with rasterio.open(output_filepath, 'w', **kwargs) as dst:\n",
    "                    for i in range(1, src.count + 1):\n",
    "                        reproject(\n",
    "                            source=rasterio.band(src, i),\n",
    "                            destination=rasterio.band(dst, i),\n",
    "                            src_transform=src.transform,\n",
    "                            src_crs=src.crs,\n",
    "                            dst_transform=transform,\n",
    "                            dst_crs=new_crs,\n",
    "                            resampling=Resampling.nearest)\n",
    "                        dst.tags(i).update(src.tags(i))\n",
    "            \n",
    "            # Copiar archivos .aux.xml si existen\n",
    "            aux_xml_filepath = input_filepath + '.aux.xml'\n",
    "            if os.path.exists(aux_xml_filepath):\n",
    "                shutil.copy(aux_xml_filepath, output_filepath + '.aux.xml')\n",
    "                \n",
    "            print(f'Reprojected {filename} to {new_crs} and saved to {output_filepath}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojected Bosques Arauco_Bosque 1_2022-10-10.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 1_2022-10-10.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2022-04-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2022-04-08.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 3A_2023-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 3A_2023-03-14.tif\n",
      "Reprojected Incendios_Chiguayante 1_2022-01-11.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 1_2022-01-11.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 3A_2023-02-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 3A_2023-02-02.tif\n",
      "Reprojected Incendios_Chiguayante 1_2023-03-29.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 1_2023-03-29.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2022-03-09.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2022-03-09.tif\n",
      "Reprojected Provoque_Tala 1_2021-04-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 1_2021-04-03.tif\n",
      "Reprojected Incendios_Chiguayante 2_2022-03-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 2_2022-03-02.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 5A_2023-02-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 5A_2023-02-02.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 7A_2023-05-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 7A_2023-05-03.tif\n",
      "Reprojected Bosques Arauco_Bosque 1_2022-01-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 1_2022-01-08.tif\n",
      "Reprojected Incendios_Chiguayante 1_2022-01-06.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 1_2022-01-06.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 3_2022-05-28.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 3_2022-05-28.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 1_2023-02-22.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 1_2023-02-22.tif\n",
      "Reprojected Bosques Arauco_Bosque 1_2022-03-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 1_2022-03-24.tif\n",
      "Reprojected Incendios_Chiguayante 4_2022-12-12.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 4_2022-12-12.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 2A_2023-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 2A_2023-03-14.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 3_2022-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 3_2022-03-14.tif\n",
      "Reprojected Provoque_Tala 3_2021-10-30.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 3_2021-10-30.tif\n",
      "Reprojected Provoque_Tala 7_2023-04-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 7_2023-04-03.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 1_2023-02-27.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 1_2023-02-27.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 1A_2023-03-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 1A_2023-03-24.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 3_2022-03-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 3_2022-03-24.tif\n",
      "Reprojected Provoque_Tala 6_2022-12-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 6_2022-12-24.tif\n",
      "Reprojected Provoque_Tala 7_2022-08-21.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 7_2022-08-21.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2022-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2022-03-14.tif\n",
      "Reprojected Provoque_Tala 2_2022-03-09.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 2_2022-03-09.tif\n",
      "Reprojected Provoque_Tala 1_2021-01-13.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 1_2021-01-13.tif\n",
      "Reprojected Provoque_Tala 2_2023-04-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 2_2023-04-08.tif\n",
      "Reprojected Incendios_Chiguayante 4_2022-12-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 4_2022-12-14.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 5A_2023-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 5A_2023-03-14.tif\n",
      "Reprojected Bosques Arauco_Bosque 2_2023-02-07.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 2_2023-02-07.tif\n",
      "Reprojected Incendios_Chiguayante 4_2022-10-10.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 4_2022-10-10.tif\n",
      "Reprojected Bosques Arauco_Bosque 1_2022-01-18.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 1_2022-01-18.tif\n",
      "Reprojected Provoque_Tala 3_2021-01-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 3_2021-01-08.tif\n",
      "Reprojected Incendios_Chiguayante 2_2022-03-09.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 2_2022-03-09.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 4A_2023-01-13.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 4A_2023-01-13.tif\n",
      "Reprojected Incendios_Chiguayante 4_2022-12-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 4_2022-12-24.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 2A_2022-10-30.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 2A_2022-10-30.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2023-04-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2023-04-08.tif\n",
      "Reprojected Incendios_Chiguayante 4_2022-10-13.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 4_2022-10-13.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 3_2022-04-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 3_2022-04-03.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 2A_2023-01-23.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 2A_2023-01-23.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 6A_2023-02-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 6A_2023-02-02.tif\n",
      "Reprojected Provoque_Tala 2_2022-01-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 2_2022-01-08.tif\n",
      "Reprojected Provoque_Tala 2_2021-01-23.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 2_2021-01-23.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 3_2023-03-29.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 3_2023-03-29.tif\n",
      "Reprojected Provoque_Tala 4_2021-11-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 4_2021-11-14.tif\n",
      "Reprojected Provoque_Tala 6_2022-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 6_2022-03-14.tif\n",
      "Reprojected Incendios_Chiguayante 3_2023-02-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 3_2023-02-02.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 3A_2022-12-04.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 3A_2022-12-04.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 1A_2023-01-28.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 1A_2023-01-28.tif\n",
      "Reprojected Incendios_Chiguayante 3_2023-04-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 3_2023-04-03.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2022-05-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2022-05-03.tif\n",
      "Reprojected Provoque_Tala 7_2021-11-19.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 7_2021-11-19.tif\n",
      "Reprojected Incendios_Chiguayante 4_2022-01-06.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 4_2022-01-06.tif\n",
      "Reprojected Incendios_Chiguayante 1_2023-02-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 1_2023-02-02.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2022-03-19.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2022-03-19.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 4A_2023-03-04.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 4A_2023-03-04.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 6A_2023-03-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 6A_2023-03-24.tif\n",
      "Reprojected Incendios_Chiguayante 3_2023-02-27.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 3_2023-02-27.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 2A_2023-02-02.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 2A_2023-02-02.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 2_2022-08-21.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 2_2022-08-21.tif\n",
      "Reprojected Incendios_Chiguayante 1_2023-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Chiguayante 1_2023-03-14.tif\n",
      "Reprojected Provoque_Tala 2_2021-04-03.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 2_2021-04-03.tif\n",
      "Reprojected Incendios_Santa Juana Oeste 7A_2023-02-17.tif to EPSG:4326 and saved to data/output/labels/tiff/Incendios_Santa Juana Oeste 7A_2023-02-17.tif\n",
      "Reprojected Provoque_Tala 4_2021-01-08.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 4_2021-01-08.tif\n",
      "Reprojected Bosques Bio Bio_Bosque 3_2022-04-28.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Bio Bio_Bosque 3_2022-04-28.tif\n",
      "Reprojected Provoque_Tala 7_2021-08-01.tif to EPSG:4326 and saved to data/output/labels/tiff/Provoque_Tala 7_2021-08-01.tif\n",
      "Reprojected Bosques Arauco_Bosque 1_2023-03-24.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 1_2023-03-24.tif\n",
      "Reprojected Bosques Arauco_Bosque 2_2022-03-14.tif to EPSG:4326 and saved to data/output/labels/tiff/Bosques Arauco_Bosque 2_2022-03-14.tif\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'data/output/labels/tiff/EPSG_3857/'\n",
    "output_folder = 'data/output/labels/tiff/'\n",
    "new_crs = 'EPSG:4326'  # o cualquier otro CRS que necesites\n",
    "\n",
    "reproject_tiffs(input_folder, output_folder, new_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "import os\n",
    "\n",
    "def process_shapefiles(directory_path, remove_from_tif_path = None):\n",
    "    output_data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".shp\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                gdf = gpd.read_file(filepath)\n",
    "                \n",
    "                # Tomar la metadata del primer polígono\n",
    "                first_row = gdf.iloc[0]\n",
    "                tif_file = first_row['tif']\n",
    "                prev_tif_file = first_row['prev_tif']\n",
    "                \n",
    "                if remove_from_tif_path is not None:\n",
    "                    tif_file = tif_file.replace(remove_from_tif_path, '')\n",
    "                    prev_tif_file = prev_tif_file.replace(remove_from_tif_path, '')\n",
    "\n",
    "                raster_shape, transform, crs = get_raster_info(tif_file)\n",
    "                # Crear una máscara binaria de todos los polígonos en el shapefile\n",
    "                geometries = gdf.geometry.values\n",
    "\n",
    "                mask = geometry_mask(geometries, transform=transform, invert=True, out_shape=raster_shape)\n",
    "\n",
    "                # Guardar la metadata\n",
    "                metadata = {\n",
    "                    'zone': first_row['zone'],\n",
    "                    'region': first_row['region'],\n",
    "                    'type_index': first_row['type_index'],\n",
    "                    'label': first_row['label'],\n",
    "                    'tif': tif_file,\n",
    "                    'prev_tif': prev_tif_file,\n",
    "                    'height': raster_shape[0],\n",
    "                    'width': raster_shape[1],\n",
    "                    'mask': mask,\n",
    "                }\n",
    "\n",
    "                output_data.append(metadata)\n",
    "\n",
    "    return output_data\n",
    "\n",
    "# Función para obtener la información necesaria del archivo TIFF\n",
    "def get_raster_info(tiff_filepath):\n",
    "    with rasterio.open(tiff_filepath) as src:\n",
    "        raster_shape = src.shape\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "    return raster_shape, transform, crs\n",
    "\n",
    "import pprint\n",
    "\n",
    "output = process_shapefiles('data/output/labels', 'EPSG_3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label occurrences:\n",
      "Talado: 21 times\n",
      "Quemado: 12 times\n",
      "Bosque: 7 times\n",
      "\n",
      "True values in masks by label:\n",
      "Talado: 106764 True values\n",
      "Quemado: 316263 True values\n",
      "Bosque: 552283 True values\n",
      "\n",
      "False values in masks by label:\n",
      "Talado: 2144492 False values\n",
      "Quemado: 3259861 False values\n",
      "Bosque: 892500 False values\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_masks_and_labels(output):\n",
    "    label_true_count = defaultdict(int)  # Contador para valores True por etiqueta\n",
    "    label_false_count = defaultdict(int)  # Contador para valores False por etiqueta\n",
    "    label_occurrences = defaultdict(int)  # Contador de ocurrencias por etiqueta\n",
    "    \n",
    "    for entry in output:\n",
    "        mask = entry.get('mask')\n",
    "        label = entry.get('label')\n",
    "        \n",
    "        if mask is not None and label is not None:\n",
    "            label_true_count[label] += np.sum(mask)\n",
    "            label_false_count[label] += np.size(mask) - np.sum(mask)\n",
    "            label_occurrences[label] += 1  # Cuenta cada ocurrencia de la etiqueta\n",
    "            \n",
    "    # Imprime los resultados\n",
    "    print(\"Label occurrences:\")\n",
    "    for label, count in label_occurrences.items():\n",
    "        print(f\"{label}: {count} times\")\n",
    "        \n",
    "    print(\"\\nTrue values in masks by label:\")\n",
    "    for label, count in label_true_count.items():\n",
    "        print(f\"{label}: {count} True values\")\n",
    "        \n",
    "    print(\"\\nFalse values in masks by label:\")\n",
    "    for label, count in label_false_count.items():\n",
    "        print(f\"{label}: {count} False values\")\n",
    "\n",
    "# Asumiendo que 'output' es tu lista de diccionarios\n",
    "analyze_masks_and_labels(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def extract_masked_pixels_and_bands(tiff_path, mask):\n",
    "    \"\"\"\n",
    "    Esta función extrae los píxeles de un archivo TIFF que están dentro de las áreas de una máscara,\n",
    "    y devuelve una lista de los valores de píxeles de múltiples bandas y los nombres de las bandas.\n",
    "    \"\"\"\n",
    "    with rasterio.open(tiff_path) as src:\n",
    "        # Obtener los nombres de las bandas\n",
    "        band_names = src.descriptions\n",
    "        band_names = [f'band_{i+1}' if name is None else name for i, name in enumerate(band_names)]\n",
    "        # Leer y aplicar la máscara a todas las bandas\n",
    "        masked_pixels = []\n",
    "        for bidx in range(1, src.count+1):\n",
    "            band_data = src.read(bidx)\n",
    "            masked_pixels.append(band_data[mask])\n",
    "        \n",
    "        # Transponer la lista para que cada píxel sea una lista de valores de todas las bandas\n",
    "        masked_pixels = np.array(masked_pixels).T.tolist()\n",
    "        \n",
    "    return masked_pixels, band_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pixels_and_bands_to_metadata(output_data):\n",
    "    for entry in output_data:\n",
    "        tif_file = entry['tif']\n",
    "        prev_tif_file = entry['prev_tif']\n",
    "        mask = entry['mask']\n",
    "        \n",
    "        # Extracting pixel values and band names\n",
    "        pixels, band_names = extract_masked_pixels_and_bands(tif_file, mask)\n",
    "        \n",
    "        # Adding pixel values and band names to metadata\n",
    "        entry['pixels'] = pixels\n",
    "        entry['band_names'] = band_names\n",
    "        entry['prev_pixels'] = extract_masked_pixels_and_bands(prev_tif_file, mask)[0]\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_enriched = add_pixels_and_bands_to_metadata(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_global_pixels(output_data):\n",
    "    \"\"\"\n",
    "    Normalize pixel values globally across all entries in output_data.\n",
    "    \n",
    "    Parameters:\n",
    "    - output_data : list of dicts\n",
    "        Each entry contains 'pixels' which is a list of lists of pixel values to be normalized.\n",
    "    \n",
    "    Returns:\n",
    "    - output_data : list of dicts\n",
    "        The input list of dictionaries, but with an added key 'pixels_normalized' in each\n",
    "        dictionary containing the normalized pixel values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Find global minimum and maximum pixel values for each band\n",
    "    all_pixels = [pixel for entry in output_data for pixel in entry['pixels']]\n",
    "    all_pixels = np.array(all_pixels)\n",
    "    \n",
    "    min_global = np.min(all_pixels, axis=(0, 1))\n",
    "    max_global = np.max(all_pixels, axis=(0, 1))\n",
    "    \n",
    "    # Step 2: Normalize all pixel values using global min and max for each band\n",
    "    # Step 3: Add normalized pixel values back to metadata\n",
    "    for entry in output_data:\n",
    "        pixels = np.array(entry['pixels'])\n",
    "        pixels_normalized = (pixels - min_global) / (max_global - min_global)\n",
    "        entry['pixels_normalized'] = pixels_normalized.tolist()\n",
    "        \n",
    "    return output_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_enriched_normalized = normalize_global_pixels(output_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_labels(output_data):\n",
    "    # Inicializar el LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Extraer todas las etiquetas y ajustar el LabelEncoder\n",
    "    labels = [entry['label'] for entry in output_data]\n",
    "    le.fit(labels)\n",
    "    \n",
    "    # Transformar las etiquetas y agregarlas a la metadata\n",
    "    for entry in output_data:\n",
    "        entry['encoded_label'] = le.transform([entry['label']])[0]\n",
    "\n",
    "    return output_data, le.classes_\n",
    "\n",
    "# Ahora, la función encode_labels agregará una nueva clave 'encoded_label' a cada entrada en output_data.\n",
    "output_enriched, label_classes = encode_labels(output_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bosque' 'Quemado' 'Talado']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print (label_classes)\n",
    "print(output_enriched_normalized[5]['encoded_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02734001910219675, 0.041189111747851004, 0.05933619866284623, 0.11664278892072588, 0.1399235912129895, 0.15293696275071633, 0.07414040114613181, 0.09169054441260745, 0.11628462273161413, 0.0005969436485195798, 0.14625119388729704, 0.10828557784145176]\n"
     ]
    }
   ],
   "source": [
    "print(output_enriched_normalized[1]['pixels_normalized'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ['blue', 'green', 'red', 'nir', 'nir08', 'nir09', 'rededge1', 'rededge2', 'rededge3', 'scl', 'swir16', 'swir22']\n",
    "selected_bands = ['blue', 'green', 'red', 'nir', 'nir08', 'nir09', 'rededge1', 'rededge2', 'rededge3', 'swir16', 'swir22']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pixels: 975310\n",
      "First pixel values: [0.0508595988538682, 0.0733046800382044, 0.07175262655205349, 0.29847182425978985, 0.31530563514804205, 0.2903533906399236, 0.13658070678127984, 0.24379178605539636, 0.28581661891117477, 0.24295606494746896, 0.14804202483285578]\n",
      "Number of samples: 975310\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Asumiendo que pixels_and_labels es una lista de diccionarios donde cada diccionario tiene\n",
    "# una clave 'pixels' y una clave 'label'\n",
    "\n",
    "pixels = []\n",
    "labels = []\n",
    "\n",
    "for entry in output_enriched_normalized:\n",
    "    for pixel_values in entry['pixels_normalized']:\n",
    "        filtered_pixel = [pixel_values[band_names.index(band)] for band in selected_bands]\n",
    "        pixels.append(filtered_pixel)\n",
    "        labels.append(entry['encoded_label'])\n",
    "\n",
    "print(\"Number of pixels:\", len(pixels))\n",
    "print(f'First pixel values: {pixels[0]}')\n",
    "\n",
    "# Convertir a arrays\n",
    "X = np.array(pixels)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Number of samples:\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, max_depth=30, min_samples_split=10,\n",
       "                       n_estimators=500, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=30, min_samples_split=10,\n",
       "                       n_estimators=500, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=30, min_samples_split=10,\n",
       "                       n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestClassifier( \n",
    "    n_estimators=500, \n",
    "    min_samples_split=10, \n",
    "    min_samples_leaf=1, \n",
    "    max_depth=30, \n",
    "    bootstrap=False,\n",
    "    n_jobs=-1  # Esto permitirá que el clasificador use todos los procesadores disponibles\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "feature_selector = SelectFromModel(rf_model, threshold=-np.inf, prefit=True)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=label_classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_importance = [(selected_bands[i], importance) for i, importance in enumerate(feature_importance)]\n",
    "feature_importance = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "print(\"Características más importantes:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestClassifier( \n",
    "    n_jobs=-1  # Esto permitirá que el clasificador use todos los procesadores disponibles\n",
    ")\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Bosque       1.00      1.00      1.00    110302\n",
      "     Quemado       1.00      1.00      1.00     63311\n",
      "      Talado       0.99      0.98      0.99     21449\n",
      "\n",
      "    accuracy                           1.00    195062\n",
      "   macro avg       1.00      0.99      0.99    195062\n",
      "weighted avg       1.00      1.00      1.00    195062\n",
      "\n",
      "Accuracy: 0.9969291814910131\n",
      "Características más importantes:\n",
      "red: 0.28969100964169014\n",
      "nir09: 0.18121318422150784\n",
      "rededge3: 0.08684480667532775\n",
      "swir22: 0.07766349831951425\n",
      "nir08: 0.07433880873074439\n",
      "swir16: 0.06479004593991441\n",
      "rededge2: 0.0607084895051184\n",
      "rededge1: 0.05382040571863618\n",
      "blue: 0.049542765706678024\n",
      "nir: 0.048482835959128834\n",
      "green: 0.012904149581739579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "feature_selector = SelectFromModel(rf_model, threshold=-np.inf, prefit=True)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=label_classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_importance = [(selected_bands[i], importance) for i, importance in enumerate(feature_importance)]\n",
    "feature_importance = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "print(\"Características más importantes:\")\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    110302\n",
      "           1       0.99      0.99      0.99     63311\n",
      "           2       0.98      0.97      0.97     21449\n",
      "\n",
      "    accuracy                           0.99    195062\n",
      "   macro avg       0.99      0.99      0.99    195062\n",
      "weighted avg       0.99      0.99      0.99    195062\n",
      "\n",
      "Accuracy: 0.9936738062769787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Instanciar y entrenar el modelo SVM\n",
    "svm_model = SVC(C=500, gamma=50)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir y evaluar el modelo SVM\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"Evaluación del modelo SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3; 1/30] START C=0.1, gamma=scale.........................................\n",
      "[CV 2/3; 1/30] START C=0.1, gamma=scale.........................................\n",
      "[CV 1/3; 4/30] START C=0.1, gamma=1.............................................\n",
      "[CV 3/3; 2/30] START C=0.1, gamma=auto..........................................\n",
      "[CV 1/3; 2/30] START C=0.1, gamma=auto..........................................\n",
      "[CV 3/3; 5/30] START C=0.1, gamma=10............................................\n",
      "[CV 3/3; 3/30] START C=0.1, gamma=0.1...........................................\n",
      "[CV 1/3; 5/30] START C=0.1, gamma=10............................................\n",
      "[CV 2/3; 3/30] START C=0.1, gamma=0.1...........................................\n",
      "[CV 2/3; 6/30] START C=0.1, gamma=50............................................\n",
      "[CV 3/3; 1/30] START C=0.1, gamma=scale.........................................\n",
      "[CV 2/3; 4/30] START C=0.1, gamma=1.............................................\n",
      "[CV 2/3; 2/30] START C=0.1, gamma=auto..........................................\n",
      "[CV 3/3; 4/30] START C=0.1, gamma=1.............................................\n",
      "[CV 1/3; 3/30] START C=0.1, gamma=0.1...........................................\n",
      "[CV 3/3; 6/30] START C=0.1, gamma=50............................................\n",
      "[CV 1/3; 6/30] START C=0.1, gamma=50............................................\n",
      "[CV 2/3; 5/30] START C=0.1, gamma=10............................................\n",
      "[CV 2/3; 7/30] START C=1, gamma=scale...........................................\n",
      "[CV 1/3; 7/30] START C=1, gamma=scale...........................................\n",
      "[CV 2/3; 7/30] END ............C=1, gamma=scale;, score=0.989 total time=24.1min\n",
      "[CV 3/3; 7/30] START C=1, gamma=scale...........................................\n",
      "[CV 1/3; 5/30] END .............C=0.1, gamma=10;, score=0.986 total time=31.3min\n",
      "[CV 1/3; 8/30] START C=1, gamma=auto............................................\n",
      "[CV 1/3; 1/30] END ..........C=0.1, gamma=scale;, score=0.986 total time=33.9min\n",
      "[CV 2/3; 8/30] START C=1, gamma=auto............................................\n",
      "[CV 2/3; 1/30] END ..........C=0.1, gamma=scale;, score=0.986 total time=37.2min\n",
      "[CV 3/3; 8/30] START C=1, gamma=auto............................................\n",
      "[CV 1/3; 7/30] END ............C=1, gamma=scale;, score=0.989 total time=38.1min\n",
      "[CV 1/3; 9/30] START C=1, gamma=0.1.............................................\n",
      "[CV 3/3; 5/30] END .............C=0.1, gamma=10;, score=0.987 total time=39.3min\n",
      "[CV 2/3; 9/30] START C=1, gamma=0.1.............................................\n",
      "[CV 3/3; 7/30] END ............C=1, gamma=scale;, score=0.989 total time=17.9min\n",
      "[CV 3/3; 9/30] START C=1, gamma=0.1.............................................\n",
      "[CV 2/3; 5/30] END .............C=0.1, gamma=10;, score=0.986 total time=57.2min\n",
      "[CV 1/3; 10/30] START C=1, gamma=1..............................................\n",
      "[CV 3/3; 1/30] END ..........C=0.1, gamma=scale;, score=0.986 total time=62.2min\n",
      "[CV 2/3; 10/30] START C=1, gamma=1..............................................\n",
      "[CV 1/3; 10/30] END ...............C=1, gamma=1;, score=0.985 total time=51.4min\n",
      "[CV 3/3; 10/30] START C=1, gamma=1..............................................\n",
      "[CV 1/3; 9/30] END ..............C=1, gamma=0.1;, score=0.979 total time=77.0min\n",
      "[CV 1/3; 11/30] START C=1, gamma=10.............................................\n",
      "[CV 3/3; 4/30] END .............C=0.1, gamma=1;, score=0.980 total time=119.5min\n",
      "[CV 2/3; 11/30] START C=1, gamma=10.............................................\n",
      "[CV 1/3; 6/30] END ............C=0.1, gamma=50;, score=0.988 total time=134.6min\n",
      "[CV 3/3; 11/30] START C=1, gamma=10.............................................\n",
      "[CV 1/3; 11/30] END ..............C=1, gamma=10;, score=0.989 total time=20.8min\n",
      "[CV 1/3; 12/30] START C=1, gamma=50.............................................\n",
      "[CV 2/3; 10/30] END ...............C=1, gamma=1;, score=0.986 total time=76.7min\n",
      "[CV 2/3; 12/30] START C=1, gamma=50.............................................\n",
      "[CV 2/3; 11/30] END ..............C=1, gamma=10;, score=0.989 total time=23.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvl/tesina/.tesina/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 12/30] START C=1, gamma=50.............................................\n",
      "[CV 3/3; 8/30] END ............C=1, gamma=auto;, score=0.979 total time=109.7min\n",
      "[CV 1/3; 13/30] START C=10, gamma=scale.........................................\n",
      "[CV 3/3; 9/30] END .............C=1, gamma=0.1;, score=0.980 total time=106.7min\n",
      "[CV 2/3; 13/30] START C=10, gamma=scale.........................................\n",
      "[CV 1/3; 4/30] END .............C=0.1, gamma=1;, score=0.979 total time=149.5min\n",
      "[CV 3/3; 13/30] START C=10, gamma=scale.........................................\n",
      "[CV 3/3; 11/30] END ..............C=1, gamma=10;, score=0.989 total time=18.7min\n",
      "[CV 1/3; 14/30] START C=10, gamma=auto..........................................\n",
      "[CV 3/3; 6/30] END ............C=0.1, gamma=50;, score=0.989 total time=155.2min\n",
      "[CV 2/3; 14/30] START C=10, gamma=auto..........................................\n",
      "[CV 2/3; 12/30] END ..............C=1, gamma=50;, score=0.991 total time=17.3min\n",
      "[CV 3/3; 14/30] START C=10, gamma=auto..........................................\n",
      "[CV 1/3; 12/30] END ..............C=1, gamma=50;, score=0.990 total time=21.8min\n",
      "[CV 1/3; 15/30] START C=10, gamma=0.1...........................................\n",
      "[CV 3/3; 10/30] END ...............C=1, gamma=1;, score=0.986 total time=49.9min\n",
      "[CV 2/3; 15/30] START C=10, gamma=0.1...........................................\n",
      "[CV 1/3; 13/30] END ..........C=10, gamma=scale;, score=0.990 total time=16.4min\n",
      "[CV 3/3; 15/30] START C=10, gamma=0.1...........................................\n",
      "[CV 3/3; 13/30] END ..........C=10, gamma=scale;, score=0.990 total time=14.5min\n",
      "[CV 1/3; 16/30] START C=10, gamma=1.............................................\n",
      "[CV 2/3; 13/30] END ..........C=10, gamma=scale;, score=0.990 total time=15.6min\n",
      "[CV 2/3; 16/30] START C=10, gamma=1.............................................\n",
      "[CV 3/3; 12/30] END ..............C=1, gamma=50;, score=0.991 total time=21.6min\n",
      "[CV 3/3; 16/30] START C=10, gamma=1.............................................\n",
      "[CV 2/3; 6/30] END ............C=0.1, gamma=50;, score=0.989 total time=173.2min\n",
      "[CV 1/3; 17/30] START C=10, gamma=10............................................\n",
      "[CV 2/3; 2/30] END ..........C=0.1, gamma=auto;, score=0.971 total time=182.3min\n",
      "[CV 2/3; 17/30] START C=10, gamma=10............................................\n",
      "[CV 1/3; 8/30] END ............C=1, gamma=auto;, score=0.979 total time=151.4min\n",
      "[CV 3/3; 17/30] START C=10, gamma=10............................................\n",
      "[CV 2/3; 16/30] END ..............C=10, gamma=1;, score=0.987 total time=20.2min\n",
      "[CV 1/3; 18/30] START C=10, gamma=50............................................\n",
      "[CV 1/3; 16/30] END ..............C=10, gamma=1;, score=0.987 total time=20.7min\n",
      "[CV 2/3; 18/30] START C=10, gamma=50............................................\n",
      "[CV 1/3; 3/30] END ...........C=0.1, gamma=0.1;, score=0.971 total time=185.2min\n",
      "[CV 3/3; 18/30] START C=10, gamma=50............................................\n",
      "[CV 2/3; 9/30] END .............C=1, gamma=0.1;, score=0.979 total time=148.9min\n",
      "[CV 1/3; 19/30] START C=100, gamma=scale........................................\n",
      "[CV 1/3; 17/30] END .............C=10, gamma=10;, score=0.990 total time=15.6min\n",
      "[CV 2/3; 19/30] START C=100, gamma=scale........................................\n",
      "[CV 3/3; 16/30] END ..............C=10, gamma=1;, score=0.987 total time=25.8min\n",
      "[CV 3/3; 19/30] START C=100, gamma=scale........................................\n",
      "[CV 3/3; 14/30] END ...........C=10, gamma=auto;, score=0.984 total time=35.4min\n",
      "[CV 1/3; 20/30] START C=100, gamma=auto.........................................\n",
      "[CV 1/3; 15/30] END ............C=10, gamma=0.1;, score=0.984 total time=40.4min\n",
      "[CV 2/3; 20/30] START C=100, gamma=auto.........................................\n",
      "[CV 2/3; 17/30] END .............C=10, gamma=10;, score=0.990 total time=18.4min\n",
      "[CV 3/3; 20/30] START C=100, gamma=auto.........................................\n",
      "[CV 3/3; 17/30] END .............C=10, gamma=10;, score=0.990 total time=18.3min\n",
      "[CV 1/3; 21/30] START C=100, gamma=0.1..........................................\n",
      "[CV 2/3; 18/30] END .............C=10, gamma=50;, score=0.992 total time=20.0min\n",
      "[CV 2/3; 21/30] START C=100, gamma=0.1..........................................\n",
      "[CV 2/3; 14/30] END ...........C=10, gamma=auto;, score=0.984 total time=49.5min\n",
      "[CV 3/3; 21/30] START C=100, gamma=0.1..........................................\n",
      "[CV 1/3; 18/30] END .............C=10, gamma=50;, score=0.992 total time=21.5min\n",
      "[CV 1/3; 22/30] START C=100, gamma=1............................................\n",
      "[CV 2/3; 15/30] END ............C=10, gamma=0.1;, score=0.985 total time=51.3min\n",
      "[CV 2/3; 22/30] START C=100, gamma=1............................................\n",
      "[CV 3/3; 18/30] END .............C=10, gamma=50;, score=0.992 total time=24.6min\n",
      "[CV 3/3; 22/30] START C=100, gamma=1............................................\n",
      "[CV 1/3; 19/30] END .........C=100, gamma=scale;, score=0.991 total time=24.4min\n",
      "[CV 1/3; 23/30] START C=100, gamma=10...........................................\n",
      "[CV 2/3; 19/30] END .........C=100, gamma=scale;, score=0.991 total time=24.5min\n",
      "[CV 2/3; 23/30] START C=100, gamma=10...........................................\n",
      "[CV 1/3; 14/30] END ...........C=10, gamma=auto;, score=0.984 total time=61.3min\n",
      "[CV 3/3; 23/30] START C=100, gamma=10...........................................\n",
      "[CV 1/3; 20/30] END ..........C=100, gamma=auto;, score=0.986 total time=24.5min\n",
      "[CV 1/3; 24/30] START C=100, gamma=50...........................................\n",
      "[CV 3/3; 15/30] END ............C=10, gamma=0.1;, score=0.985 total time=53.0min\n",
      "[CV 2/3; 24/30] START C=100, gamma=50...........................................\n",
      "[CV 3/3; 19/30] END .........C=100, gamma=scale;, score=0.991 total time=29.9min\n",
      "[CV 3/3; 24/30] START C=100, gamma=50...........................................\n",
      "[CV 2/3; 4/30] END .............C=0.1, gamma=1;, score=0.980 total time=221.2min\n",
      "[CV 1/3; 25/30] START C=500, gamma=scale........................................\n",
      "[CV 3/3; 3/30] END ...........C=0.1, gamma=0.1;, score=0.972 total time=224.9min\n",
      "[CV 2/3; 25/30] START C=500, gamma=scale........................................\n",
      "[CV 1/3; 21/30] END ...........C=100, gamma=0.1;, score=0.986 total time=25.1min\n",
      "[CV 3/3; 25/30] START C=500, gamma=scale........................................\n",
      "[CV 1/3; 22/30] END .............C=100, gamma=1;, score=0.988 total time=21.3min\n",
      "[CV 1/3; 26/30] START C=500, gamma=auto.........................................\n",
      "[CV 3/3; 21/30] END ...........C=100, gamma=0.1;, score=0.986 total time=24.2min\n",
      "[CV 2/3; 26/30] START C=500, gamma=auto.........................................\n",
      "[CV 2/3; 22/30] END .............C=100, gamma=1;, score=0.989 total time=19.6min\n",
      "[CV 3/3; 26/30] START C=500, gamma=auto.........................................\n",
      "[CV 3/3; 22/30] END .............C=100, gamma=1;, score=0.989 total time=20.0min\n",
      "[CV 1/3; 27/30] START C=500, gamma=0.1..........................................\n",
      "[CV 1/3; 23/30] END ............C=100, gamma=10;, score=0.991 total time=26.9min\n",
      "[CV 2/3; 27/30] START C=500, gamma=0.1..........................................\n",
      "[CV 2/3; 23/30] END ............C=100, gamma=10;, score=0.991 total time=27.1min\n",
      "[CV 3/3; 27/30] START C=500, gamma=0.1..........................................\n",
      "[CV 3/3; 23/30] END ............C=100, gamma=10;, score=0.991 total time=27.4min\n",
      "[CV 1/3; 28/30] START C=500, gamma=1............................................\n",
      "[CV 1/3; 26/30] END ..........C=500, gamma=auto;, score=0.987 total time=23.6min\n",
      "[CV 2/3; 28/30] START C=500, gamma=1............................................\n",
      "[CV 2/3; 26/30] END ..........C=500, gamma=auto;, score=0.987 total time=22.8min\n",
      "[CV 3/3; 28/30] START C=500, gamma=1............................................\n",
      "[CV 1/3; 27/30] END ...........C=500, gamma=0.1;, score=0.987 total time=23.3min\n",
      "[CV 1/3; 29/30] START C=500, gamma=10...........................................\n",
      "[CV 3/3; 26/30] END ..........C=500, gamma=auto;, score=0.987 total time=26.8min\n",
      "[CV 2/3; 29/30] START C=500, gamma=10...........................................\n",
      "[CV 2/3; 21/30] END ...........C=100, gamma=0.1;, score=0.986 total time=57.3min\n",
      "[CV 3/3; 29/30] START C=500, gamma=10...........................................\n",
      "[CV 2/3; 27/30] END ...........C=500, gamma=0.1;, score=0.987 total time=24.5min\n",
      "[CV 1/3; 30/30] START C=500, gamma=50...........................................\n",
      "[CV 3/3; 27/30] END ...........C=500, gamma=0.1;, score=0.987 total time=25.8min\n",
      "[CV 2/3; 30/30] START C=500, gamma=50...........................................\n",
      "[CV 1/3; 28/30] END .............C=500, gamma=1;, score=0.989 total time=25.9min\n",
      "[CV 3/3; 30/30] START C=500, gamma=50...........................................\n",
      "[CV 2/3; 24/30] END ............C=100, gamma=50;, score=0.993 total time=54.5min\n",
      "[CV 1/3; 24/30] END ............C=100, gamma=50;, score=0.993 total time=60.0min\n",
      "[CV 2/3; 28/30] END .............C=500, gamma=1;, score=0.990 total time=25.3min\n",
      "[CV 2/3; 8/30] END ............C=1, gamma=auto;, score=0.979 total time=243.0min\n",
      "[CV 3/3; 28/30] END .............C=500, gamma=1;, score=0.989 total time=25.3min\n",
      "[CV 3/3; 24/30] END ............C=100, gamma=50;, score=0.993 total time=57.7min\n",
      "[CV 1/3; 25/30] END .........C=500, gamma=scale;, score=0.992 total time=60.0min\n",
      "[CV 2/3; 25/30] END .........C=500, gamma=scale;, score=0.992 total time=60.0min\n",
      "[CV 3/3; 25/30] END .........C=500, gamma=scale;, score=0.992 total time=60.9min\n",
      "[CV 3/3; 20/30] END ..........C=100, gamma=auto;, score=0.986 total time=92.8min\n",
      "[CV 3/3; 2/30] END ..........C=0.1, gamma=auto;, score=0.971 total time=294.0min\n",
      "[CV 2/3; 3/30] END ...........C=0.1, gamma=0.1;, score=0.971 total time=296.4min\n",
      "[CV 2/3; 29/30] END ............C=500, gamma=10;, score=0.992 total time=44.4min\n",
      "[CV 1/3; 29/30] END ............C=500, gamma=10;, score=0.992 total time=48.1min\n",
      "[CV 3/3; 29/30] END ............C=500, gamma=10;, score=0.992 total time=40.7min\n",
      "[CV 1/3; 2/30] END ..........C=0.1, gamma=auto;, score=0.971 total time=303.1min\n",
      "[CV 2/3; 20/30] END .........C=100, gamma=auto;, score=0.986 total time=110.2min\n",
      "[CV 1/3; 30/30] END ............C=500, gamma=50;, score=0.993 total time=58.6min\n",
      "[CV 2/3; 30/30] END ............C=500, gamma=50;, score=0.993 total time=57.2min\n",
      "[CV 3/3; 30/30] END ............C=500, gamma=50;, score=0.993 total time=56.1min\n",
      "{'C': 500, 'gamma': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir los hiperparámetros para la búsqueda\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100, 500],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1, 10, 50],\n",
    "    #'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "# Utilizar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=3, n_jobs= -1, verbose=10)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV 1/3; 2/9] START C=100, gamma=50.............................................[CV 3/3; 1/9] START C=100, gamma=10.............................................[CV 2/3; 2/9] START C=100, gamma=50.............................................[CV 2/3; 1/9] START C=100, gamma=10.............................................\n",
      "\n",
      "\n",
      "[CV 1/3; 1/9] START C=100, gamma=10.............................................\n",
      "[CV 3/3; 2/9] START C=100, gamma=50.............................................\n",
      "\n",
      "[CV 3/3; 1/9] END ..............C=100, gamma=10;, score=0.991 total time=11.9min\n",
      "[CV 1/3; 3/9] START C=100, gamma=100............................................\n",
      "[CV 2/3; 1/9] END ..............C=100, gamma=10;, score=0.991 total time=12.0min\n",
      "[CV 2/3; 3/9] START C=100, gamma=100............................................\n",
      "[CV 1/3; 1/9] END ..............C=100, gamma=10;, score=0.991 total time=12.1min\n",
      "[CV 3/3; 3/9] START C=100, gamma=100............................................\n",
      "[CV 2/3; 2/9] END ..............C=100, gamma=50;, score=0.993 total time=22.1min\n",
      "[CV 1/3; 4/9] START C=500, gamma=10.............................................\n",
      "[CV 3/3; 2/9] END ..............C=100, gamma=50;, score=0.993 total time=22.3min\n",
      "[CV 2/3; 4/9] START C=500, gamma=10.............................................\n",
      "[CV 1/3; 2/9] END ..............C=100, gamma=50;, score=0.993 total time=22.8min\n",
      "[CV 3/3; 4/9] START C=500, gamma=10.............................................\n",
      "[CV 1/3; 3/9] END .............C=100, gamma=100;, score=0.994 total time=29.3min\n",
      "[CV 1/3; 5/9] START C=500, gamma=50.............................................\n",
      "[CV 2/3; 3/9] END .............C=100, gamma=100;, score=0.994 total time=30.3min\n",
      "[CV 2/3; 5/9] START C=500, gamma=50.............................................\n",
      "[CV 3/3; 3/9] END .............C=100, gamma=100;, score=0.994 total time=31.6min\n",
      "[CV 3/3; 5/9] START C=500, gamma=50.............................................\n",
      "[CV 2/3; 4/9] END ..............C=500, gamma=10;, score=0.992 total time=26.0min\n",
      "[CV 1/3; 6/9] START C=500, gamma=100............................................\n",
      "[CV 3/3; 4/9] END ..............C=500, gamma=10;, score=0.992 total time=25.6min\n",
      "[CV 2/3; 6/9] START C=500, gamma=100............................................\n",
      "[CV 1/3; 4/9] END ..............C=500, gamma=10;, score=0.992 total time=26.5min\n",
      "[CV 3/3; 6/9] START C=500, gamma=100............................................\n",
      "[CV 1/3; 5/9] END ..............C=500, gamma=50;, score=0.993 total time=53.6min\n",
      "[CV 1/3; 7/9] START C=1000, gamma=10............................................\n",
      "[CV 2/3; 5/9] END ..............C=500, gamma=50;, score=0.993 total time=55.1min\n",
      "[CV 2/3; 7/9] START C=1000, gamma=10............................................\n",
      "[CV 3/3; 5/9] END ..............C=500, gamma=50;, score=0.993 total time=55.4min\n",
      "[CV 3/3; 7/9] START C=1000, gamma=10............................................\n",
      "[CV 1/3; 6/9] END .............C=500, gamma=100;, score=0.994 total time=59.2min\n",
      "[CV 1/3; 8/9] START C=1000, gamma=50............................................\n",
      "[CV 2/3; 6/9] END .............C=500, gamma=100;, score=0.994 total time=59.8min\n",
      "[CV 2/3; 8/9] START C=1000, gamma=50............................................\n",
      "[CV 3/3; 6/9] END .............C=500, gamma=100;, score=0.994 total time=62.0min\n",
      "[CV 3/3; 8/9] START C=1000, gamma=50............................................\n",
      "[CV 1/3; 7/9] END .............C=1000, gamma=10;, score=0.992 total time=41.5min\n",
      "[CV 1/3; 9/9] START C=1000, gamma=100...........................................\n",
      "[CV 2/3; 7/9] END .............C=1000, gamma=10;, score=0.992 total time=40.2min\n",
      "[CV 2/3; 9/9] START C=1000, gamma=100...........................................\n",
      "[CV 3/3; 7/9] END .............C=1000, gamma=10;, score=0.992 total time=39.3min\n",
      "[CV 3/3; 9/9] START C=1000, gamma=100...........................................\n",
      "[CV 2/3; 8/9] END .............C=1000, gamma=50;, score=0.994 total time=82.0min\n",
      "[CV 1/3; 8/9] END .............C=1000, gamma=50;, score=0.994 total time=84.2min\n",
      "[CV 3/3; 8/9] END .............C=1000, gamma=50;, score=0.994 total time=85.1min\n",
      "[CV 1/3; 9/9] END ............C=1000, gamma=100;, score=0.994 total time=73.0min\n",
      "[CV 2/3; 9/9] END ............C=1000, gamma=100;, score=0.994 total time=72.8min\n",
      "[CV 3/3; 9/9] END ............C=1000, gamma=100;, score=0.994 total time=73.1min\n",
      "{'C': 1000, 'gamma': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir los hiperparámetros para la búsqueda\n",
    "param_grid_svm = {\n",
    "    'C': [ 100, 500, 1000],\n",
    "    'gamma': [ 10, 50, 100],\n",
    "    #'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "# Utilizar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=3, n_jobs= 6, verbose=10)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jvl/tesina/Train_model.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneighbors\u001b[39;00m \u001b[39mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Instanciar y entrenar el modelo KNN\u001b[39;00m\n",
      "File \u001b[0;32m~/tesina/.tesina/lib/python3.10/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m ]\n",
      "File \u001b[0;32m~/tesina/.tesina/lib/python3.10/site-packages/sklearn/base.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n",
      "File \u001b[0;32m~/tesina/.tesina/lib/python3.10/site-packages/numpy/__init__.py:140\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m# Allow distributors to run custom init code\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init\n\u001b[0;32m--> 140\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n",
      "File \u001b[0;32m~/tesina/.tesina/lib/python3.10/site-packages/numpy/core/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m         env_added\u001b[39m.\u001b[39mappend(envkey)\n\u001b[1;32m     22\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m multiarray\n\u001b[1;32m     24\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     25\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n",
      "File \u001b[0;32m~/tesina/.tesina/lib/python3.10/site-packages/numpy/core/multiarray.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mCreate the numpy.core.multiarray namespace for backward compatibility. In v1.16\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mthe multiarray and umath c-extension modules were merged into a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m overrides\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _multiarray_umath\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_multiarray_umath\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n",
      "File \u001b[0;32m~/tesina/.tesina/lib/python3.10/site-packages/numpy/core/overrides.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_multiarray_umath\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_inspect\u001b[39;00m \u001b[39mimport\u001b[39;00m getargspec\n\u001b[1;32m     11\u001b[0m ARRAY_FUNCTION_ENABLED \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(\n\u001b[1;32m     12\u001b[0m     \u001b[39mint\u001b[39m(os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mNUMPY_EXPERIMENTAL_ARRAY_FUNCTION\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV 1/3; 1/30] START metric=euclidean, n_neighbors=3, weights=uniform...........\n",
      "[CV 2/3; 1/30] START metric=euclidean, n_neighbors=3, weights=uniform...........\n",
      "[CV 3/3; 2/30] START metric=euclidean, n_neighbors=3, weights=distance..........\n",
      "[CV 3/3; 1/30] START metric=euclidean, n_neighbors=3, weights=uniform...........\n",
      "[CV 2/3; 2/30] START metric=euclidean, n_neighbors=3, weights=distance..........\n",
      "[CV 1/3; 2/30] START metric=euclidean, n_neighbors=3, weights=distance..........\n",
      "[CV 3/3; 2/30] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.994 total time=  30.3s\n",
      "[CV 1/3; 3/30] START metric=euclidean, n_neighbors=5, weights=uniform...........\n",
      "[CV 2/3; 2/30] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.994 total time=  30.7s\n",
      "[CV 2/3; 3/30] START metric=euclidean, n_neighbors=5, weights=uniform...........\n",
      "[CV 1/3; 2/30] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.994 total time=  30.9s\n",
      "[CV 3/3; 3/30] START metric=euclidean, n_neighbors=5, weights=uniform...........\n",
      "[CV 1/3; 1/30] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.992 total time=  34.8s\n",
      "[CV 1/3; 4/30] START metric=euclidean, n_neighbors=5, weights=distance..........\n",
      "[CV 2/3; 1/30] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.992 total time=  35.3s\n",
      "[CV 2/3; 4/30] START metric=euclidean, n_neighbors=5, weights=distance..........\n",
      "[CV 3/3; 1/30] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.992 total time=  35.4s\n",
      "[CV 3/3; 4/30] START metric=euclidean, n_neighbors=5, weights=distance..........\n",
      "[CV 1/3; 4/30] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.994 total time=  36.7s\n",
      "[CV 1/3; 5/30] START metric=euclidean, n_neighbors=7, weights=uniform...........\n",
      "[CV 1/3; 3/30] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.991 total time=  41.6s\n",
      "[CV 2/3; 5/30] START metric=euclidean, n_neighbors=7, weights=uniform...........\n",
      "[CV 2/3; 4/30] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.994 total time=  37.1s\n",
      "[CV 3/3; 5/30] START metric=euclidean, n_neighbors=7, weights=uniform...........\n",
      "[CV 3/3; 4/30] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.994 total time=  37.1s\n",
      "[CV 1/3; 6/30] START metric=euclidean, n_neighbors=7, weights=distance..........\n",
      "[CV 2/3; 3/30] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.991 total time=  42.4s\n",
      "[CV 2/3; 6/30] START metric=euclidean, n_neighbors=7, weights=distance..........\n",
      "[CV 3/3; 3/30] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.992 total time=  42.3s\n",
      "[CV 3/3; 6/30] START metric=euclidean, n_neighbors=7, weights=distance..........\n",
      "[CV 1/3; 6/30] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.994 total time=  42.4s\n",
      "[CV 1/3; 7/30] START metric=euclidean, n_neighbors=10, weights=uniform..........\n",
      "[CV 3/3; 6/30] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.994 total time=  42.6s\n",
      "[CV 2/3; 7/30] START metric=euclidean, n_neighbors=10, weights=uniform..........\n",
      "[CV 2/3; 6/30] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.994 total time=  42.9s\n",
      "[CV 3/3; 7/30] START metric=euclidean, n_neighbors=10, weights=uniform..........\n",
      "[CV 1/3; 5/30] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.991 total time=  47.0s\n",
      "[CV 1/3; 8/30] START metric=euclidean, n_neighbors=10, weights=distance.........\n",
      "[CV 2/3; 5/30] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.991 total time=  47.7s\n",
      "[CV 2/3; 8/30] START metric=euclidean, n_neighbors=10, weights=distance.........\n",
      "[CV 3/3; 5/30] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.991 total time=  47.5s\n",
      "[CV 3/3; 8/30] START metric=euclidean, n_neighbors=10, weights=distance.........\n",
      "[CV 1/3; 8/30] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.994 total time=  47.8s\n",
      "[CV 1/3; 9/30] START metric=euclidean, n_neighbors=20, weights=uniform..........\n",
      "[CV 2/3; 8/30] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.994 total time=  48.2s\n",
      "[CV 2/3; 9/30] START metric=euclidean, n_neighbors=20, weights=uniform..........\n",
      "[CV 3/3; 8/30] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.994 total time=  47.9s\n",
      "[CV 3/3; 9/30] START metric=euclidean, n_neighbors=20, weights=uniform..........\n",
      "[CV 1/3; 7/30] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.990 total time=  53.0s\n",
      "[CV 1/3; 10/30] START metric=euclidean, n_neighbors=20, weights=distance........\n",
      "[CV 2/3; 7/30] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.990 total time=  53.9s\n",
      "[CV 2/3; 10/30] START metric=euclidean, n_neighbors=20, weights=distance........\n",
      "[CV 3/3; 7/30] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.990 total time=  53.8s\n",
      "[CV 3/3; 10/30] START metric=euclidean, n_neighbors=20, weights=distance........\n",
      "[CV 1/3; 10/30] END metric=euclidean, n_neighbors=20, weights=distance;, score=0.993 total time= 1.0min\n",
      "[CV 1/3; 11/30] START metric=manhattan, n_neighbors=3, weights=uniform..........\n",
      "[CV 1/3; 9/30] END metric=euclidean, n_neighbors=20, weights=uniform;, score=0.989 total time= 1.1min\n",
      "[CV 2/3; 11/30] START metric=manhattan, n_neighbors=3, weights=uniform..........\n",
      "[CV 2/3; 10/30] END metric=euclidean, n_neighbors=20, weights=distance;, score=0.993 total time= 1.0min\n",
      "[CV 3/3; 11/30] START metric=manhattan, n_neighbors=3, weights=uniform..........\n",
      "[CV 3/3; 10/30] END metric=euclidean, n_neighbors=20, weights=distance;, score=0.993 total time= 1.0min\n",
      "[CV 1/3; 12/30] START metric=manhattan, n_neighbors=3, weights=distance.........\n",
      "[CV 3/3; 9/30] END metric=euclidean, n_neighbors=20, weights=uniform;, score=0.990 total time= 1.1min\n",
      "[CV 2/3; 12/30] START metric=manhattan, n_neighbors=3, weights=distance.........\n",
      "[CV 2/3; 9/30] END metric=euclidean, n_neighbors=20, weights=uniform;, score=0.989 total time= 1.1min\n",
      "[CV 3/3; 12/30] START metric=manhattan, n_neighbors=3, weights=distance.........\n",
      "[CV 1/3; 12/30] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.995 total time= 1.2min\n",
      "[CV 1/3; 13/30] START metric=manhattan, n_neighbors=5, weights=uniform..........\n",
      "[CV 1/3; 11/30] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.993 total time= 1.3min\n",
      "[CV 2/3; 13/30] START metric=manhattan, n_neighbors=5, weights=uniform..........\n",
      "[CV 2/3; 12/30] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.995 total time= 1.2min\n",
      "[CV 3/3; 13/30] START metric=manhattan, n_neighbors=5, weights=uniform..........\n",
      "[CV 3/3; 12/30] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.995 total time= 1.2min\n",
      "[CV 1/3; 14/30] START metric=manhattan, n_neighbors=5, weights=distance.........\n",
      "[CV 2/3; 11/30] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.994 total time= 1.3min\n",
      "[CV 2/3; 14/30] START metric=manhattan, n_neighbors=5, weights=distance.........\n",
      "[CV 3/3; 11/30] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.994 total time= 1.3min\n",
      "[CV 3/3; 14/30] START metric=manhattan, n_neighbors=5, weights=distance.........\n",
      "[CV 1/3; 14/30] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.995 total time= 1.6min\n",
      "[CV 1/3; 15/30] START metric=manhattan, n_neighbors=7, weights=uniform..........\n",
      "[CV 2/3; 14/30] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.995 total time= 1.6min\n",
      "[CV 2/3; 15/30] START metric=manhattan, n_neighbors=7, weights=uniform..........\n",
      "[CV 3/3; 14/30] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.995 total time= 1.6min\n",
      "[CV 3/3; 15/30] START metric=manhattan, n_neighbors=7, weights=uniform..........\n",
      "[CV 1/3; 13/30] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.992 total time= 1.7min\n",
      "[CV 1/3; 16/30] START metric=manhattan, n_neighbors=7, weights=distance.........\n",
      "[CV 3/3; 13/30] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.993 total time= 1.7min\n",
      "[CV 2/3; 16/30] START metric=manhattan, n_neighbors=7, weights=distance.........\n",
      "[CV 2/3; 13/30] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.992 total time= 1.8min\n",
      "[CV 3/3; 16/30] START metric=manhattan, n_neighbors=7, weights=distance.........\n",
      "[CV 1/3; 16/30] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.995 total time= 1.9min\n",
      "[CV 1/3; 17/30] START metric=manhattan, n_neighbors=10, weights=uniform.........\n",
      "[CV 2/3; 16/30] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.995 total time= 1.9min\n",
      "[CV 2/3; 17/30] START metric=manhattan, n_neighbors=10, weights=uniform.........\n",
      "[CV 1/3; 15/30] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.992 total time= 2.0min\n",
      "[CV 3/3; 17/30] START metric=manhattan, n_neighbors=10, weights=uniform.........\n",
      "[CV 2/3; 15/30] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.992 total time= 1.9min\n",
      "[CV 1/3; 18/30] START metric=manhattan, n_neighbors=10, weights=distance........\n",
      "[CV 3/3; 15/30] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.992 total time= 2.0min\n",
      "[CV 2/3; 18/30] START metric=manhattan, n_neighbors=10, weights=distance........\n",
      "[CV 3/3; 16/30] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.995 total time= 1.9min\n",
      "[CV 3/3; 18/30] START metric=manhattan, n_neighbors=10, weights=distance........\n",
      "[CV 1/3; 18/30] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.994 total time= 2.1min\n",
      "[CV 1/3; 19/30] START metric=manhattan, n_neighbors=20, weights=uniform.........\n",
      "[CV 1/3; 17/30] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.991 total time= 2.2min\n",
      "[CV 2/3; 19/30] START metric=manhattan, n_neighbors=20, weights=uniform.........\n",
      "[CV 2/3; 18/30] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.995 total time= 2.2min\n",
      "[CV 3/3; 19/30] START metric=manhattan, n_neighbors=20, weights=uniform.........\n",
      "[CV 2/3; 17/30] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.991 total time= 2.2min\n",
      "[CV 1/3; 20/30] START metric=manhattan, n_neighbors=20, weights=distance........\n",
      "[CV 3/3; 18/30] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.995 total time= 2.2min\n",
      "[CV 2/3; 20/30] START metric=manhattan, n_neighbors=20, weights=distance........\n",
      "[CV 3/3; 17/30] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.991 total time= 2.2min\n",
      "[CV 3/3; 20/30] START metric=manhattan, n_neighbors=20, weights=distance........\n",
      "[CV 1/3; 19/30] END metric=manhattan, n_neighbors=20, weights=uniform;, score=0.990 total time= 2.7min\n",
      "[CV 1/3; 21/30] START metric=minkowski, n_neighbors=3, weights=uniform..........\n",
      "[CV 1/3; 20/30] END metric=manhattan, n_neighbors=20, weights=distance;, score=0.994 total time= 2.6min\n",
      "[CV 2/3; 21/30] START metric=minkowski, n_neighbors=3, weights=uniform..........\n",
      "[CV 3/3; 20/30] END metric=manhattan, n_neighbors=20, weights=distance;, score=0.994 total time= 2.6min\n",
      "[CV 3/3; 21/30] START metric=minkowski, n_neighbors=3, weights=uniform..........\n",
      "[CV 2/3; 20/30] END metric=manhattan, n_neighbors=20, weights=distance;, score=0.994 total time= 2.6min\n",
      "[CV 1/3; 22/30] START metric=minkowski, n_neighbors=3, weights=distance.........\n",
      "[CV 3/3; 19/30] END metric=manhattan, n_neighbors=20, weights=uniform;, score=0.990 total time= 2.7min\n",
      "[CV 2/3; 22/30] START metric=minkowski, n_neighbors=3, weights=distance.........\n",
      "[CV 2/3; 19/30] END metric=manhattan, n_neighbors=20, weights=uniform;, score=0.989 total time= 2.7min\n",
      "[CV 3/3; 22/30] START metric=minkowski, n_neighbors=3, weights=distance.........\n",
      "[CV 1/3; 22/30] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.994 total time=  28.9s\n",
      "[CV 1/3; 23/30] START metric=minkowski, n_neighbors=5, weights=uniform..........\n",
      "[CV 1/3; 21/30] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.992 total time=  34.0s\n",
      "[CV 2/3; 23/30] START metric=minkowski, n_neighbors=5, weights=uniform..........\n",
      "[CV 2/3; 21/30] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.992 total time=  34.3s\n",
      "[CV 3/3; 23/30] START metric=minkowski, n_neighbors=5, weights=uniform..........\n",
      "[CV 2/3; 22/30] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.994 total time=  29.1s\n",
      "[CV 1/3; 24/30] START metric=minkowski, n_neighbors=5, weights=distance.........\n",
      "[CV 3/3; 22/30] END metric=minkowski, n_neighbors=3, weights=distance;, score=0.994 total time=  29.1s\n",
      "[CV 2/3; 24/30] START metric=minkowski, n_neighbors=5, weights=distance.........\n",
      "[CV 3/3; 21/30] END metric=minkowski, n_neighbors=3, weights=uniform;, score=0.992 total time=  34.3s\n",
      "[CV 3/3; 24/30] START metric=minkowski, n_neighbors=5, weights=distance.........\n",
      "[CV 1/3; 24/30] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.994 total time=  37.0s\n",
      "[CV 1/3; 25/30] START metric=minkowski, n_neighbors=7, weights=uniform..........\n",
      "[CV 2/3; 24/30] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.994 total time=  37.4s\n",
      "[CV 2/3; 25/30] START metric=minkowski, n_neighbors=7, weights=uniform..........\n",
      "[CV 1/3; 23/30] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.991 total time=  41.7s\n",
      "[CV 3/3; 25/30] START metric=minkowski, n_neighbors=7, weights=uniform..........\n",
      "[CV 3/3; 24/30] END metric=minkowski, n_neighbors=5, weights=distance;, score=0.994 total time=  36.7s\n",
      "[CV 1/3; 26/30] START metric=minkowski, n_neighbors=7, weights=distance.........\n",
      "[CV 2/3; 23/30] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.991 total time=  42.1s\n",
      "[CV 2/3; 26/30] START metric=minkowski, n_neighbors=7, weights=distance.........\n",
      "[CV 3/3; 23/30] END metric=minkowski, n_neighbors=5, weights=uniform;, score=0.992 total time=  42.1s\n",
      "[CV 3/3; 26/30] START metric=minkowski, n_neighbors=7, weights=distance.........\n",
      "[CV 1/3; 26/30] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.994 total time=  43.3s\n",
      "[CV 1/3; 27/30] START metric=minkowski, n_neighbors=10, weights=uniform.........\n",
      "[CV 2/3; 26/30] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.994 total time=  43.5s\n",
      "[CV 2/3; 27/30] START metric=minkowski, n_neighbors=10, weights=uniform.........\n",
      "[CV 3/3; 26/30] END metric=minkowski, n_neighbors=7, weights=distance;, score=0.994 total time=  43.2s\n",
      "[CV 3/3; 27/30] START metric=minkowski, n_neighbors=10, weights=uniform.........\n",
      "[CV 1/3; 25/30] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.991 total time=  48.4s\n",
      "[CV 1/3; 28/30] START metric=minkowski, n_neighbors=10, weights=distance........\n",
      "[CV 2/3; 25/30] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.991 total time=  49.6s\n",
      "[CV 2/3; 28/30] START metric=minkowski, n_neighbors=10, weights=distance........\n",
      "[CV 3/3; 25/30] END metric=minkowski, n_neighbors=7, weights=uniform;, score=0.991 total time=  49.4s\n",
      "[CV 3/3; 28/30] START metric=minkowski, n_neighbors=10, weights=distance........\n",
      "[CV 1/3; 28/30] END metric=minkowski, n_neighbors=10, weights=distance;, score=0.994 total time=  50.4s\n",
      "[CV 1/3; 29/30] START metric=minkowski, n_neighbors=20, weights=uniform.........\n",
      "[CV 1/3; 27/30] END metric=minkowski, n_neighbors=10, weights=uniform;, score=0.990 total time=  55.8s\n",
      "[CV 2/3; 29/30] START metric=minkowski, n_neighbors=20, weights=uniform.........\n",
      "[CV 2/3; 28/30] END metric=minkowski, n_neighbors=10, weights=distance;, score=0.994 total time=  50.5s\n",
      "[CV 3/3; 29/30] START metric=minkowski, n_neighbors=20, weights=uniform.........\n",
      "[CV 3/3; 28/30] END metric=minkowski, n_neighbors=10, weights=distance;, score=0.994 total time=  50.2s\n",
      "[CV 1/3; 30/30] START metric=minkowski, n_neighbors=20, weights=distance........\n",
      "[CV 3/3; 27/30] END metric=minkowski, n_neighbors=10, weights=uniform;, score=0.990 total time=  55.5s\n",
      "[CV 2/3; 30/30] START metric=minkowski, n_neighbors=20, weights=distance........\n",
      "[CV 2/3; 27/30] END metric=minkowski, n_neighbors=10, weights=uniform;, score=0.990 total time=  56.0s\n",
      "[CV 3/3; 30/30] START metric=minkowski, n_neighbors=20, weights=distance........\n",
      "[CV 1/3; 30/30] END metric=minkowski, n_neighbors=20, weights=distance;, score=0.993 total time= 1.0min\n",
      "[CV 3/3; 30/30] END metric=minkowski, n_neighbors=20, weights=distance;, score=0.993 total time= 1.0min\n",
      "[CV 2/3; 30/30] END metric=minkowski, n_neighbors=20, weights=distance;, score=0.993 total time= 1.0min\n",
      "[CV 1/3; 29/30] END metric=minkowski, n_neighbors=20, weights=uniform;, score=0.989 total time= 1.1min\n",
      "[CV 3/3; 29/30] END metric=minkowski, n_neighbors=20, weights=uniform;, score=0.990 total time= 1.1min\n",
      "[CV 2/3; 29/30] END metric=minkowski, n_neighbors=20, weights=uniform;, score=0.989 total time= 1.1min\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Definir los hiperparámetros para la búsqueda\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 10, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Utilizar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=3, verbose=10)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(grid_search_knn.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    110302\n",
      "           1       1.00      1.00      1.00     63311\n",
      "           2       0.99      0.99      0.99     21449\n",
      "\n",
      "    accuracy                           1.00    195062\n",
      "   macro avg       0.99      0.99      0.99    195062\n",
      "weighted avg       1.00      1.00      1.00    195062\n",
      "\n",
      "Accuracy: 0.9965498149306374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Instanciar y entrenar el modelo KNN\n",
    "knn_model = KNeighborsClassifier(metric= 'manhattan', n_neighbors= 3, weights= 'distance')\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir y evaluar el modelo KNN\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "print(\"Evaluación del modelo KNN:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jvl/tesina/Train_model.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Obtener los coeficientes de las características\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m coeficients \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mcoef_[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Crear una lista de tuplas con el nombre de la característica y su coeficiente\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jvl/tesina/Train_model.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m feature_coef \u001b[39m=\u001b[39m [(band_names[i], coef) \u001b[39mfor\u001b[39;00m i, coef \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(coeficients)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtener los coeficientes de las características\n",
    "coeficients = rf_model.coef_[0]\n",
    "\n",
    "# Crear una lista de tuplas con el nombre de la característica y su coeficiente\n",
    "feature_coef = [(band_names[i], coef) for i, coef in enumerate(coeficients)]\n",
    "\n",
    "# Ordenar las características por su coeficiente absoluto en orden descendente\n",
    "feature_coef = sorted(feature_coef, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Imprimir las características más relevantes\n",
    "print(\"Características más relevantes:\")\n",
    "for feature, coef in feature_coef:\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [5, 10, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV 2/3; 3/10] START bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300\n",
      "[CV 1/3; 6/10] START bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 2/10] START bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500\n",
      "[CV 3/3; 3/10] START bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300\n",
      "[CV 3/3; 1/10] START bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300\n",
      "[CV 2/3; 1/10] START bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300\n",
      "[CV 2/3; 4/10] START bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 5/10] START bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500\n",
      "[CV 3/3; 4/10] START bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 1/10] START bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300\n",
      "[CV 3/3; 2/10] START bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 4/10] START bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500\n",
      "[CV 2/3; 5/10] START bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500\n",
      "[CV 3/3; 6/10] START bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500\n",
      "[CV 3/3; 5/10] START bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500\n",
      "[CV 1/3; 3/10] START bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300\n",
      "[CV 2/3; 6/10] START bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500\n",
      "[CV 2/3; 2/10] START bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 7/10] START bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500\n",
      "[CV 2/3; 7/10] START bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500\n",
      "[CV 3/3; 3/10] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.988 total time=10.2min\n",
      "[CV 3/3; 7/10] START bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500\n",
      "[CV 2/3; 3/10] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.988 total time=10.3min\n",
      "[CV 1/3; 8/10] START bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300\n",
      "[CV 1/3; 3/10] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.988 total time=10.8min\n",
      "[CV 2/3; 8/10] START bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300\n",
      "[CV 3/3; 5/10] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.988 total time=17.1min\n",
      "[CV 3/3; 8/10] START bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300\n",
      "[CV 2/3; 5/10] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.988 total time=17.3min\n",
      "[CV 1/3; 9/10] START bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300\n",
      "[CV 3/3; 1/10] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.994 total time=17.3min\n",
      "[CV 2/3; 9/10] START bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300\n",
      "[CV 2/3; 7/10] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.988 total time=17.6min\n",
      "[CV 3/3; 9/10] START bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300\n",
      "[CV 2/3; 1/10] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.994 total time=17.7min\n",
      "[CV 1/3; 10/10] START bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 1/10] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.994 total time=17.9min\n",
      "[CV 2/3; 10/10] START bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 5/10] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500;, score=0.989 total time=18.1min\n",
      "[CV 3/3; 10/10] START bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500\n",
      "[CV 1/3; 7/10] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.988 total time=18.2min\n",
      "[CV 3/3; 4/10] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.988 total time=22.9min\n",
      "[CV 1/3; 4/10] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.989 total time=23.3min\n",
      "[CV 2/3; 4/10] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.988 total time=23.7min\n",
      "[CV 1/3; 8/10] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.989 total time=13.6min\n",
      "[CV 2/3; 8/10] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.988 total time=13.6min\n",
      "[CV 3/3; 7/10] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.988 total time=16.2min\n",
      "[CV 1/3; 2/10] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.994 total time=26.8min\n",
      "[CV 2/3; 2/10] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.994 total time=26.8min\n",
      "[CV 3/3; 2/10] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500;, score=0.994 total time=27.0min\n",
      "[CV 3/3; 8/10] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.988 total time=11.0min\n",
      "[CV 1/3; 9/10] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.989 total time=11.0min\n",
      "[CV 3/3; 9/10] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.989 total time=10.8min\n",
      "[CV 2/3; 9/10] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.988 total time=11.0min\n",
      "[CV 2/3; 6/10] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.996 total time=31.8min\n",
      "[CV 1/3; 6/10] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.996 total time=32.0min\n",
      "[CV 3/3; 6/10] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.996 total time=32.2min\n",
      "[CV 3/3; 10/10] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.988 total time=14.2min\n",
      "[CV 1/3; 10/10] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.989 total time=14.7min\n",
      "[CV 2/3; 10/10] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.988 total time=14.5min\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 30, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Utiliza RandomizedSearchCV para búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=10, cv=3, n_jobs=-1, verbose=10)\n",
    "\n",
    "# O utiliza GridSearchCV para búsqueda exhaustiva\n",
    "# grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a tus datos de entrenamiento\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Supongamos que tienes tus etiquetas reales en y_test y las predicciones en y_pred\n",
    "confusion_mat = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "\n",
    "# Utiliza seaborn para visualizar la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=label_classes, yticklabels=label_classes)\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Etiquetas Verdaderas')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvl/tesina/.tesina/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 80.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jvl/tesina/.tesina/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jvl/tesina/.tesina/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/jvl/tesina/.tesina/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/jvl/tesina/.tesina/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l1', 'l2'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jvl/tesina/.tesina/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.96369053        nan 0.90787252        nan 0.97581083\n",
      "        nan 0.91800399        nan 0.98247766        nan 0.94727339\n",
      "        nan 0.98526968        nan 0.95329662]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para la Regresión Logística:\n",
      "{'C': 10.0, 'fit_intercept': True, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Entrenar Regresión Logística\n",
    "log_reg_model = LogisticRegression(max_iter=100000)\n",
    "#log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros para la búsqueda\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0],\n",
    "    'penalty': ['None', 'l2'],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros usando validación cruzada\n",
    "grid_search = GridSearchCV(log_reg_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros para la Regresión Logística:\")\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Logistic Regression:\n",
      "Accuracy: 0.9836314246182358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    110554\n",
      "           1       0.96      0.97      0.96     31054\n",
      "           2       0.95      0.91      0.93     15950\n",
      "\n",
      "    accuracy                           0.98    157558\n",
      "   macro avg       0.97      0.96      0.96    157558\n",
      "weighted avg       0.98      0.98      0.98    157558\n",
      "\n",
      "Evaluation of Random Forest:\n",
      "Accuracy: 0.9969661965752294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    110554\n",
      "           1       0.99      1.00      0.99     31054\n",
      "           2       0.99      0.98      0.99     15950\n",
      "\n",
      "    accuracy                           1.00    157558\n",
      "   macro avg       1.00      0.99      0.99    157558\n",
      "weighted avg       1.00      1.00      1.00    157558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluación\n",
    "for model, name in zip([log_reg_model, rf_model], [\"Logistic Regression\", \"Random Forest\"]):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Evaluation of {name}:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
